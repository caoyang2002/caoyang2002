<!doctype html><html class="not-ready lg:text-base close" style=--bg:#faf8f1 lang=zh-CN dir=ltr><style>body{background-image:url(/images/ui/background.jpg);background-repeat:no-repeat;background-position:50%;background-attachment:fixed;background-size:cover;min-height:100vh}html,body{min-height:100vh}</style><script src=https://cdn.tailwindcss.com></script><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>人工智能中的数学基础 - 短松江月</title><meta name=theme-color><meta name=description content='1. 向量空间 (Vector Space)
数学概念
向量空间是线性代数的核心概念，它是一个满足特定运算规则的集合。
定义要素：

域 F：通常是实数域 ℝ 或复数域 ℂ
向量集合 V：非空集合
两种运算：

加法：V × V → V
数乘：F × V → V



八条公理详解：

加法交换律：u + v = v + u
加法结合律：(u+v)+w = u+(v+w)
加法单位元：存在零向量 0
加法逆元：每个向量都有相反向量
数乘结合律：a(bv) = (ab)v
数乘单位元：1·v = v
数乘对向量加法的分配律：a(u+v) = au + av
数乘对域加法的分配律：(a+b)v = av + bv

在机器学习中的应用

特征向量：每个数据样本可以表示为向量空间中的一个点
权重向量：神经网络的权重形成向量空间
梯度下降：在参数空间中进行优化

Python实现










 



         



       



 



     



 



 



     



     



       



 



 



 



 



     



 



     



     



 



         



 



     



 






    
    
        import numpy as np
from typing import List, Union

class VectorSpace:
    """
    向量空间的实现
    这里我们实现 R^n 上的向量空间
    """
    
    def __init__(self, dimension: int):
        """
        初始化向量空间
        
        参数:
            dimension: 向量空间的维数
        """
        self.dimension = dimension
        self.zero_vector = np.zeros(dimension)
    
    def add(self, u: np.ndarray, v: np.ndarray) -> np.ndarray:
        """
        向量加法
        验证加法交换律: u + v = v + u
        """
        self._check_dimension(u)
        self._check_dimension(v)
        return u + v
    
    def scalar_multiply(self, scalar: float, v: np.ndarray) -> np.ndarray:
        """
        数乘运算
        """
        self._check_dimension(v)
        return scalar * v
    
    def additive_inverse(self, v: np.ndarray) -> np.ndarray:
        """
        加法逆元（相反向量）
        """
        self._check_dimension(v)
        return -v
    
    def _check_dimension(self, v: np.ndarray):
        """检查向量维度是否匹配"""
        if len(v) != self.dimension:
            raise ValueError(f"向量维度应为 {self.dimension}, 但得到 {len(v)}")
    
    def verify_axioms(self, u: np.ndarray, v: np.ndarray, w: np.ndarray, 
                     a: float, b: float) -> dict:
        """
        验证向量空间的八条公理
        
        返回:
            包含每条公理验证结果的字典
        """
        results = {}
        
        # 公理1: 加法交换律
        results[&#39;commutative&#39;] = np.allclose(
            self.add(u, v), 
            self.add(v, u)
        )
        
        # 公理2: 加法结合律
        results[&#39;associative_add&#39;] = np.allclose(
            self.add(self.add(u, v), w),
            self.add(u, self.add(v, w))
        )
        
        # 公理3: 加法单位元
        results[&#39;additive_identity&#39;] = np.allclose(
            self.add(v, self.zero_vector),
            v
        )
        
        # 公理4: 加法逆元
        results[&#39;additive_inverse&#39;] = np.allclose(
            self.add(v, self.additive_inverse(v)),
            self.zero_vector
        )
        
        # 公理5: 数乘结合律
        results[&#39;associative_scalar&#39;] = np.allclose(
            self.scalar_multiply(a, self.scalar_multiply(b, v)),
            self.scalar_multiply(a * b, v)
        )
        
        # 公理6: 数乘单位元
        results[&#39;scalar_identity&#39;] = np.allclose(
            self.scalar_multiply(1, v),
            v
        )
        
        # 公理7: 数乘对向量加法的分配律
        results[&#39;distributive_vector&#39;] = np.allclose(
            self.scalar_multiply(a, self.add(u, v)),
            self.add(self.scalar_multiply(a, u), self.scalar_multiply(a, v))
        )
        
        # 公理8: 数乘对域加法的分配律
        results[&#39;distributive_scalar&#39;] = np.allclose(
            self.scalar_multiply(a + b, v),
            self.add(self.scalar_multiply(a, v), self.scalar_multiply(b, v))
        )
        
        return results


# 示例使用
if __name__ == "__main__":
    # 创建3维向量空间
    V = VectorSpace(dimension=3)
    
    # 创建测试向量
    u = np.array([1.0, 2.0, 3.0])
    v = np.array([4.0, 5.0, 6.0])
    w = np.array([7.0, 8.0, 9.0])
    
    # 测试标量
    a, b = 2.0, 3.0
    
    print("=" * 50)
    print("向量空间公理验证")
    print("=" * 50)
    
    # 验证所有公理
    results = V.verify_axioms(u, v, w, a, b)
    
    for axiom, is_valid in results.items():
        print(f"{axiom:25s}: {&#39;✓ 通过&#39; if is_valid else &#39;✗ 失败&#39;}")
    
    print("\n" + "=" * 50)
    print("基本运算示例")
    print("=" * 50)
    
    print(f"u = {u}")
    print(f"v = {v}")
    print(f"u + v = {V.add(u, v)}")
    print(f"2 * u = {V.scalar_multiply(2, u)}")
    print(f"-v = {V.additive_inverse(v)}")
    

    
    
    
        
            
                运行
                
                    
                    
                
            
        
    
    
        
    
    



2. 线性组合 (Linear Combination)
数学概念
线性组合是向量空间中最基本的运算之一。'><meta name=author content="simons"><script src=/js/code-flag-handler.js defer></script><link rel="preload stylesheet" as=style href=/bundle.min.66b2dab2c6bacce8963b2d2af9ecbb257a82f2249ddd6035c697d7658f3c988c.css><link rel=preload as=image href=/theme.png><link rel=preload as=image href=/about/avatar.jpg><link rel=preload as=image href=/twitter.svg><link rel=preload as=image href=/github.svg><link rel=preload as=image href=/instagram.svg><link rel=preload as=image href=/rss.svg><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/monokai.min.css><script defer src=https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js onload=hljs.highlightAll()></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/lisp.min.js></script><script defer src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/sql.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",()=>renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1,errorCallback:(e)=>{console.warn("KaTeX 渲染错误:",e)}}))</script><link rel=icon href=/favicon.ico><link rel=apple-touch-icon href=/apple-touch-icon.png><meta name=generator content="Hugo 0.155.1"><meta itemprop=name content="人工智能中的数学基础"><meta itemprop=description content="糟糕，写文章的时候忘记添加描述了！！！"><meta itemprop=datePublished content="2026-02-02T14:33:33+08:00"><meta itemprop=dateModified content="2026-02-02T17:36:04+08:00"><meta itemprop=wordCount content="11501"><meta itemprop=keywords content="暂无"><meta property="og:url" content="https://simons.qzz.io/post/2026/02/basic_concepts/"><meta property="og:site_name" content="短松江月"><meta property="og:title" content="人工智能中的数学基础"><meta property="og:description" content="糟糕，写文章的时候忘记添加描述了！！！"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-02T14:33:33+08:00"><meta property="article:modified_time" content="2026-02-02T17:36:04+08:00"><meta property="article:tag" content="暂无"><meta name=twitter:card content="summary"><meta name=twitter:title content="人工智能中的数学基础"><meta name=twitter:description content="糟糕，写文章的时候忘记添加描述了！！！"><link rel=canonical href=https://simons.qzz.io/post/2026/02/basic_concepts/></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-12 px-8 lg:justify-center"><div class="relative z-50 ltr:mr-auto rtl:ml-auto flex items-center max-w-[--w]"><a class="-translate-y-[1px] text-2xl font-medium" href=https://simons.qzz.io/>短松江月</a><div class="btn-dark text-[0] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer
[background:url(/theme.png)_left_center/_auto_theme('spacing.6')_no-repeat]
[transition:_background-position_0.4s_steps(5)]
dark:[background-position:right]" role=button aria-label="Toggle theme"></div></div><div class="btn-menu relative z-50 ltr:-mr-8 rtl:-ml-8 flex h-[3rem] w-[5rem]
shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role=button aria-label="Toggle menu"></div><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-0 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse"><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/>首页
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/posts/>文章随笔
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/resources/>技术资源
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/aerospace/>航天航空
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/software/>软件工程
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/hardware/>硬件嵌入式
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/creative/>视觉创意
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/marketing/>广告营销
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/culture/>传统文化
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/about/>关于我
</a><a class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal header-menu" href=/search/>站内搜索</a><div class=language-selector><div class="inline-block text-left dropdown"><div><p class=selected-language>Chinese</p></div><div style=background-color:red;z-index:1000></div></div><script>const dropdownButton=document.getElementById("dropdownButton"),dropdownMenu=document.getElementById("dropdownMenu"),dropdownIcon=document.querySelector(".dropdown-icon");dropdownButton.addEventListener("click",function(){dropdownMenu.classList.toggle("show"),dropdownButton.parentElement.classList.toggle("open")}),dropdownMenu.querySelectorAll("li").forEach(e=>{e.addEventListener("click",function(){dropdownButton.textContent=e.textContent+" ",dropdownButton.appendChild(dropdownIcon),dropdownMenu.classList.remove("show"),dropdownButton.parentElement.classList.remove("open");const t=e.getAttribute("data-value");console.log("Selected Language:",t)})}),document.addEventListener("click",function(e){!dropdownButton.contains(e.target)&&!dropdownMenu.contains(e.target)&&(dropdownMenu.classList.remove("show"),dropdownButton.parentElement.classList.remove("open"))})</script><style>.dropdown{display:inline-block;margin:0}.dropdown-menu{background-color:#fff;border:1px solid #ddd;border-radius:8px;padding:0;margin:0;display:none}.dropdown-menu.show{display:block}.dropdown-menu li{padding:.2rem;cursor:pointer;color:#333}.dropdown-menu>li:hover{background-color:initial}.selected-language:hover{color:#0042da}</style></div></nav></div><style>.language-selector{position:relative;display:inline-block;z-index:10}.language-selector .dropdown-menu{display:none;position:absolute;top:100%;right:0;background-color:#fff;border:1px solid #ddd;border-radius:4px;box-shadow:0 4px 8px rgba(0,0,0,.1);z-index:50}.language-selector:hover .dropdown-menu{display:block}</style></header><script>const htmlClass=document.documentElement.classList;setTimeout(()=>htmlClass.remove("not-ready"),10);const btnMenu=document.querySelector(".btn-menu");btnMenu&&btnMenu.addEventListener("click",()=>{htmlClass.toggle("open"),htmlClass.toggle("close")});const themeManager={metaTheme:document.querySelector('meta[name="theme-color"]'),lightBg:"#faf8f1".replace(/"/g,""),btnDark:document.querySelector(".btn-dark"),init(){const e=window.matchMedia("(prefers-color-scheme: dark)"),t=localStorage.getItem("dark")==="true"||localStorage.getItem("dark")===null&&e.matches;this.setTheme(t),e.addEventListener("change",e=>this.setTheme(e.matches)),this.btnDark&&this.btnDark.addEventListener("click",()=>this.toggleTheme())},setTheme(e){this.metaTheme?.setAttribute("content",e?"#000":this.lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},toggleTheme(){this.setTheme(localStorage.getItem("dark")!=="true")}};themeManager.init()</script><style>header{position:fixed;top:0;left:0;right:0;z-index:50;width:100vw;backdrop-filter:blur(8px);-webkit-backdrop-filter:blur(8px);background:rgba(255,255,255,.5);box-shadow:0 4px 30px rgba(0,0,0,.1)}.header-menu:hover{color:#0042da}</style><div class="relative flex justify-start max-w-[90vw] px-8"><main class="min-h-[calc(100vh-5rem)] py-12 prose prose-neutral flex-1 dark:prose-invert text-left max-w-full lg:max-w-4xl xl:max-w-6xl"><article class=text-left><div class="mb-14 mt-8"><h1 class="!my-0 pb-2.5">人工智能中的数学基础</h1><div class="text-xs antialiased opacity-60"><time>2026年2月2日星期一
</time><span class=mx-1>&#183;</span>
<span>simons
</span><span class=mx-1>&#183;</span>
<span class=post-date>本文共 11501
个字 ， 预计需要阅读 23
分钟</span></div><span class="text-md antialiased opacity-60"><a href=https://simons.qzz.io/tags/%E6%9A%82%E6%97%A0 class="mb-2 ltr:mr-1.5 rtl:ml-1.5 px-3 py-1 rounded-lg no-underline bg-black/[3%] hover:bg-black/[6%] dark:bg-white/[8%] dark:hover:bg-white/[12%]">暂无</a></span></div><section><h2 id=1-向量空间-vector-space>1. 向量空间 (Vector Space)</h2><h3 id=数学概念>数学概念</h3><p><strong>向量空间</strong>是线性代数的核心概念，它是一个满足特定运算规则的集合。</p><p><strong>定义要素</strong>：</p><ul><li><strong>域 F</strong>：通常是实数域 ℝ 或复数域 ℂ</li><li><strong>向量集合 V</strong>：非空集合</li><li><strong>两种运算</strong>：<ul><li>加法：V × V → V</li><li>数乘：F × V → V</li></ul></li></ul><p><strong>八条公理详解</strong>：</p><ol><li><strong>加法交换律</strong>：u + v = v + u</li><li><strong>加法结合律</strong>：(u+v)+w = u+(v+w)</li><li><strong>加法单位元</strong>：存在零向量 0</li><li><strong>加法逆元</strong>：每个向量都有相反向量</li><li><strong>数乘结合律</strong>：a(bv) = (ab)v</li><li><strong>数乘单位元</strong>：1·v = v</li><li><strong>数乘对向量加法的分配律</strong>：a(u+v) = au + av</li><li><strong>数乘对域加法的分配律</strong>：(a+b)v = av + bv</li></ol><h3 id=在机器学习中的应用>在机器学习中的应用</h3><ul><li><strong>特征向量</strong>：每个数据样本可以表示为向量空间中的一个点</li><li><strong>权重向量</strong>：神经网络的权重形成向量空间</li><li><strong>梯度下降</strong>：在参数空间中进行优化</li></ul><h3 id=python实现>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>import numpy as np
from typing import List, Union

class VectorSpace:
    &#34;&#34;&#34;
    向量空间的实现
    这里我们实现 R^n 上的向量空间
    &#34;&#34;&#34;
    
    def __init__(self, dimension: int):
        &#34;&#34;&#34;
        初始化向量空间
        
        参数:
            dimension: 向量空间的维数
        &#34;&#34;&#34;
        self.dimension = dimension
        self.zero_vector = np.zeros(dimension)
    
    def add(self, u: np.ndarray, v: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        向量加法
        验证加法交换律: u &#43; v = v &#43; u
        &#34;&#34;&#34;
        self._check_dimension(u)
        self._check_dimension(v)
        return u &#43; v
    
    def scalar_multiply(self, scalar: float, v: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        数乘运算
        &#34;&#34;&#34;
        self._check_dimension(v)
        return scalar * v
    
    def additive_inverse(self, v: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        加法逆元（相反向量）
        &#34;&#34;&#34;
        self._check_dimension(v)
        return -v
    
    def _check_dimension(self, v: np.ndarray):
        &#34;&#34;&#34;检查向量维度是否匹配&#34;&#34;&#34;
        if len(v) != self.dimension:
            raise ValueError(f&#34;向量维度应为 {self.dimension}, 但得到 {len(v)}&#34;)
    
    def verify_axioms(self, u: np.ndarray, v: np.ndarray, w: np.ndarray, 
                     a: float, b: float) -&gt; dict:
        &#34;&#34;&#34;
        验证向量空间的八条公理
        
        返回:
            包含每条公理验证结果的字典
        &#34;&#34;&#34;
        results = {}
        
        # 公理1: 加法交换律
        results[&#39;commutative&#39;] = np.allclose(
            self.add(u, v), 
            self.add(v, u)
        )
        
        # 公理2: 加法结合律
        results[&#39;associative_add&#39;] = np.allclose(
            self.add(self.add(u, v), w),
            self.add(u, self.add(v, w))
        )
        
        # 公理3: 加法单位元
        results[&#39;additive_identity&#39;] = np.allclose(
            self.add(v, self.zero_vector),
            v
        )
        
        # 公理4: 加法逆元
        results[&#39;additive_inverse&#39;] = np.allclose(
            self.add(v, self.additive_inverse(v)),
            self.zero_vector
        )
        
        # 公理5: 数乘结合律
        results[&#39;associative_scalar&#39;] = np.allclose(
            self.scalar_multiply(a, self.scalar_multiply(b, v)),
            self.scalar_multiply(a * b, v)
        )
        
        # 公理6: 数乘单位元
        results[&#39;scalar_identity&#39;] = np.allclose(
            self.scalar_multiply(1, v),
            v
        )
        
        # 公理7: 数乘对向量加法的分配律
        results[&#39;distributive_vector&#39;] = np.allclose(
            self.scalar_multiply(a, self.add(u, v)),
            self.add(self.scalar_multiply(a, u), self.scalar_multiply(a, v))
        )
        
        # 公理8: 数乘对域加法的分配律
        results[&#39;distributive_scalar&#39;] = np.allclose(
            self.scalar_multiply(a &#43; b, v),
            self.add(self.scalar_multiply(a, v), self.scalar_multiply(b, v))
        )
        
        return results


# 示例使用
if __name__ == &#34;__main__&#34;:
    # 创建3维向量空间
    V = VectorSpace(dimension=3)
    
    # 创建测试向量
    u = np.array([1.0, 2.0, 3.0])
    v = np.array([4.0, 5.0, 6.0])
    w = np.array([7.0, 8.0, 9.0])
    
    # 测试标量
    a, b = 2.0, 3.0
    
    print(&#34;=&#34; * 50)
    print(&#34;向量空间公理验证&#34;)
    print(&#34;=&#34; * 50)
    
    # 验证所有公理
    results = V.verify_axioms(u, v, w, a, b)
    
    for axiom, is_valid in results.items():
        print(f&#34;{axiom:25s}: {&#39;✓ 通过&#39; if is_valid else &#39;✗ 失败&#39;}&#34;)
    
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;基本运算示例&#34;)
    print(&#34;=&#34; * 50)
    
    print(f&#34;u = {u}&#34;)
    print(f&#34;v = {v}&#34;)
    print(f&#34;u &#43; v = {V.add(u, v)}&#34;)
    print(f&#34;2 * u = {V.scalar_multiply(2, u)}&#34;)
    print(f&#34;-v = {V.additive_inverse(v)}&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><hr><h2 id=2-线性组合-linear-combination>2. 线性组合 (Linear Combination)</h2><h3 id=数学概念-1>数学概念</h3><p><strong>线性组合</strong>是向量空间中最基本的运算之一。</p><p><strong>定义</strong>：给定向量 v₁, v₂, &mldr;, vₖ 和标量 a₁, a₂, &mldr;, aₖ，表达式：</p>$$a_1v_1 + a_2v_2 + ... + a_kv_k$$<p>称为这些向量的线性组合。</p><h3 id=在机器学习中的应用-1>在机器学习中的应用</h3><ul><li><strong>神经网络</strong>：每个神经元的输出是输入的线性组合加上激活函数</li><li><strong>线性回归</strong>：预测值是特征的线性组合</li><li><strong>PCA</strong>：主成分是原始特征的线性组合</li></ul><h3 id=python实现-1>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class LinearCombination:
    &#34;&#34;&#34;线性组合的实现&#34;&#34;&#34;
    
    @staticmethod
    def compute(vectors: List[np.ndarray], coefficients: List[float]) -&gt; np.ndarray:
        &#34;&#34;&#34;
        计算向量的线性组合
        
        参数:
            vectors: 向量列表 [v1, v2, ..., vk]
            coefficients: 系数列表 [a1, a2, ..., ak]
        
        返回:
            线性组合结果: a1*v1 &#43; a2*v2 &#43; ... &#43; ak*vk
        &#34;&#34;&#34;
        if len(vectors) != len(coefficients):
            raise ValueError(&#34;向量数量必须与系数数量相同&#34;)
        
        if not vectors:
            raise ValueError(&#34;至少需要一个向量&#34;)
        
        # 初始化结果为零向量
        result = np.zeros_like(vectors[0])
        
        # 累加每个向量的标量倍
        for coeff, vector in zip(coefficients, vectors):
            result &#43;= coeff * vector
        
        return result
    
    @staticmethod
    def matrix_form(vectors: List[np.ndarray], coefficients: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        使用矩阵形式计算线性组合
        更高效的实现方式
        
        参数:
            vectors: 向量列表
            coefficients: 系数数组
        
        返回:
            线性组合结果
        &#34;&#34;&#34;
        # 将向量列表转换为矩阵（每列是一个向量）
        matrix = np.column_stack(vectors)
        return matrix @ coefficients


# 示例：线性回归
class SimpleLinearRegression:
    &#34;&#34;&#34;
    简单线性回归：使用线性组合进行预测
    y = w1*x1 &#43; w2*x2 &#43; ... &#43; wn*xn &#43; b
    &#34;&#34;&#34;
    
    def __init__(self, n_features: int):
        self.n_features = n_features
        self.weights = None
        self.bias = None
    
    def fit(self, X: np.ndarray, y: np.ndarray):
        &#34;&#34;&#34;
        使用最小二乘法拟合模型
        
        参数:
            X: 特征矩阵 (n_samples, n_features)
            y: 目标值 (n_samples,)
        &#34;&#34;&#34;
        # 添加偏置项（在X前面添加一列1）
        X_with_bias = np.column_stack([np.ones(len(X)), X])
        
        # 最小二乘解: θ = (X^T X)^(-1) X^T y
        theta = np.linalg.inv(X_with_bias.T @ X_with_bias) @ X_with_bias.T @ y
        
        self.bias = theta[0]
        self.weights = theta[1:]
    
    def predict(self, X: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        预测：计算特征的线性组合
        
        参数:
            X: 特征矩阵 (n_samples, n_features)
        
        返回:
            预测值 (n_samples,)
        &#34;&#34;&#34;
        if self.weights is None:
            raise ValueError(&#34;模型尚未训练，请先调用 fit()&#34;)
        
        # y = X @ w &#43; b (线性组合)
        return X @ self.weights &#43; self.bias


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;线性组合示例&#34;)
    print(&#34;=&#34; * 50)
    
    # 示例1: 基本线性组合
    v1 = np.array([1, 0, 0])
    v2 = np.array([0, 1, 0])
    v3 = np.array([0, 0, 1])
    
    vectors = [v1, v2, v3]
    coefficients = [2, 3, 4]
    
    result = LinearCombination.compute(vectors, coefficients)
    print(f&#34;2*v1 &#43; 3*v2 &#43; 4*v3 = {result}&#34;)
    
    # 示例2: 线性回归
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;线性回归示例（使用线性组合）&#34;)
    print(&#34;=&#34; * 50)
    
    # 生成示例数据
    np.random.seed(42)
    X_train = np.random.randn(100, 3)  # 100个样本，3个特征
    true_weights = np.array([2.0, -1.0, 0.5])
    true_bias = 1.0
    y_train = X_train @ true_weights &#43; true_bias &#43; np.random.randn(100) * 0.1
    
    # 训练模型
    model = SimpleLinearRegression(n_features=3)
    model.fit(X_train, y_train)
    
    print(f&#34;真实权重: {true_weights}&#34;)
    print(f&#34;学习权重: {model.weights}&#34;)
    print(f&#34;真实偏置: {true_bias}&#34;)
    print(f&#34;学习偏置: {model.bias}&#34;)
    
    # 预测
    X_test = np.random.randn(5, 3)
    predictions = model.predict(X_test)
    print(f&#34;\n测试样本预测: {predictions[:5]}&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><hr><h2 id=3-生成空间-span>3. 生成空间 (Span)</h2><h3 id=数学概念-2>数学概念</h3><p><strong>生成空间</strong>（或张成空间）是由一组向量的所有线性组合构成的集合。</p><p><strong>定义</strong>：</p>$$\text{Span}\{v_1, ..., v_k\} = \{a_1v_1 + ... + a_kv_k \mid a_1, ..., a_k \in F\}$$<p><strong>性质</strong>：</p><ul><li>Span 是一个子空间</li><li>它是包含这些向量的最小子空间</li><li>如果向量组线性相关，移除某些向量不改变 Span</li></ul><h3 id=在机器学习中的应用-2>在机器学习中的应用</h3><ul><li><strong>特征空间</strong>：所有可能的特征向量构成的空间</li><li><strong>列空间</strong>：矩阵的列向量张成的空间（重要用于理解线性变换）</li><li><strong>降维</strong>：PCA 寻找能够张成数据主要变化方向的向量</li></ul><h3 id=python实现-2>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class Span:
    &#34;&#34;&#34;生成空间的实现&#34;&#34;&#34;
    
    def __init__(self, vectors: List[np.ndarray]):
        &#34;&#34;&#34;
        初始化生成空间
        
        参数:
            vectors: 生成该空间的向量列表
        &#34;&#34;&#34;
        self.generators = [v.copy() for v in vectors]
        self.dimension = len(vectors[0]) if vectors else 0
        
        # 计算生成空间的基（通过行化简）
        self.basis = self._compute_basis()
    
    def _compute_basis(self) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        使用行化简找到生成空间的一组基
        
        返回:
            基向量列表
        &#34;&#34;&#34;
        if not self.generators:
            return []
        
        # 将向量组成矩阵（每行是一个向量）
        matrix = np.array(self.generators)
        
        # 使用QR分解找到线性无关的向量
        # 或使用行化简的方法
        return self._row_reduce_to_basis(matrix)
    
    def _row_reduce_to_basis(self, matrix: np.ndarray, tol: float = 1e-10) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        通过行化简提取基向量
        
        参数:
            matrix: 向量矩阵（每行是一个向量）
            tol: 容差，用于判断是否为零
        
        返回:
            基向量列表
        &#34;&#34;&#34;
        # 使用SVD找到秩和基
        U, s, Vt = np.linalg.svd(matrix, full_matrices=False)
        
        # 找到非零奇异值
        rank = np.sum(s &gt; tol)
        
        # 提取对应的左奇异向量作为基
        # 实际上应该用原始向量的线性无关组合
        # 这里我们简化处理
        basis_vectors = []
        current_rank = 0
        
        for i, vec in enumerate(self.generators):
            if current_rank &gt;= rank:
                break
            
            # 检查这个向量是否与已有基线性无关
            if not basis_vectors:
                basis_vectors.append(vec)
                current_rank &#43;= 1
            else:
                # 投影到已有基的正交补空间
                projection = vec.copy()
                for basis_vec in basis_vectors:
                    projection -= (np.dot(projection, basis_vec) / 
                                 np.dot(basis_vec, basis_vec)) * basis_vec
                
                if np.linalg.norm(projection) &gt; tol:
                    basis_vectors.append(vec)
                    current_rank &#43;= 1
        
        return basis_vectors
    
    def contains(self, vector: np.ndarray, tol: float = 1e-10) -&gt; bool:
        &#34;&#34;&#34;
        判断向量是否在生成空间中
        
        参数:
            vector: 待检查的向量
            tol: 数值容差
        
        返回:
            True 如果向量在生成空间中
        &#34;&#34;&#34;
        if not self.basis:
            return np.allclose(vector, 0, atol=tol)
        
        # 构造基矩阵
        basis_matrix = np.column_stack(self.basis)
        
        # 尝试求解 basis_matrix @ x = vector
        try:
            x, residuals, rank, s = np.linalg.lstsq(basis_matrix, vector, rcond=None)
            
            # 检查残差
            if len(residuals) &gt; 0:
                return residuals[0] &lt; tol
            else:
                # 如果方程恰好有解
                reconstruction = basis_matrix @ x
                return np.allclose(reconstruction, vector, atol=tol)
        except np.linalg.LinAlgError:
            return False
    
    def get_coordinates(self, vector: np.ndarray) -&gt; Union[np.ndarray, None]:
        &#34;&#34;&#34;
        获取向量在基下的坐标
        
        参数:
            vector: 向量
        
        返回:
            坐标数组，如果向量不在空间中则返回 None
        &#34;&#34;&#34;
        if not self.contains(vector):
            return None
        
        basis_matrix = np.column_stack(self.basis)
        coordinates, _, _, _ = np.linalg.lstsq(basis_matrix, vector, rcond=None)
        
        return coordinates
    
    def get_dimension(self) -&gt; int:
        &#34;&#34;&#34;返回生成空间的维数&#34;&#34;&#34;
        return len(self.basis)


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;生成空间示例&#34;)
    print(&#34;=&#34; * 50)
    
    # 示例1: R^3 中的平面
    v1 = np.array([1.0, 0.0, 0.0])
    v2 = np.array([0.0, 1.0, 0.0])
    
    plane = Span([v1, v2])
    
    print(f&#34;生成空间维数: {plane.get_dimension()}&#34;)
    print(f&#34;基向量数量: {len(plane.basis)}&#34;)
    
    # 测试包含性
    test_vectors = [
        np.array([2.0, 3.0, 0.0]),  # 在平面内
        np.array([1.0, 1.0, 1.0]),  # 不在平面内
        np.array([0.0, 0.0, 0.0]),  # 零向量
    ]
    
    for i, vec in enumerate(test_vectors):
        in_span = plane.contains(vec)
        print(f&#34;\n向量 {vec} 是否在生成空间中: {in_span}&#34;)
        if in_span:
            coords = plane.get_coordinates(vec)
            print(f&#34;  坐标: {coords}&#34;)
    
    # 示例2: 线性相关的向量组
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;线性相关向量组的生成空间&#34;)
    print(&#34;=&#34; * 50)
    
    u1 = np.array([1.0, 0.0, 0.0])
    u2 = np.array([0.0, 1.0, 0.0])
    u3 = np.array([2.0, 3.0, 0.0])  # u3 = 2*u1 &#43; 3*u2 (线性相关)
    
    span_redundant = Span([u1, u2, u3])
    print(f&#34;原始向量数: 3&#34;)
    print(f&#34;生成空间维数: {span_redundant.get_dimension()}&#34;)
    print(f&#34;基向量数量: {len(span_redundant.basis)}&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><hr><h2 id=4-欧几里得空间-euclidean-space>4. 欧几里得空间 (Euclidean Space)</h2><h3 id=数学概念-3>数学概念</h3><p><strong>欧几里得空间</strong>是配备了内积（点积）的实向量空间，通常指 ℝⁿ。</p><p><strong>核心定义</strong>：</p><ol><li><p><strong>内积（点积）</strong>：</p>$$\mathbf{x} \cdot \mathbf{y} = \sum_{i=1}^n x_i y_i$$</li><li><p><strong>范数（长度）</strong>：</p>$$\|\mathbf{x}\| = \sqrt{\mathbf{x} \cdot \mathbf{x}} = \sqrt{\sum_{i=1}^n x_i^2}$$</li><li><p><strong>距离</strong>：</p>$$d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\|$$</li></ol><p><strong>内积的性质</strong>：</p><ul><li>对称性：⟨x, y⟩ = ⟨y, x⟩</li><li>线性性：⟨ax + by, z⟩ = a⟨x, z⟩ + b⟨y, z⟩</li><li>正定性：⟨x, x⟩ ≥ 0，等号成立当且仅当 x = 0</li></ul><h3 id=在机器学习中的应用-3>在机器学习中的应用</h3><ul><li><strong>相似度计算</strong>：余弦相似度基于内积</li><li><strong>距离度量</strong>：欧氏距离用于聚类、KNN等</li><li><strong>优化</strong>：梯度是函数增长最快的方向（基于内积）</li><li><strong>正则化</strong>：L2正则化使用欧氏范数</li></ul><h3 id=python实现-3>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class EuclideanSpace:
    &#34;&#34;&#34;欧几里得空间的实现&#34;&#34;&#34;
    
    def __init__(self, dimension: int):
        &#34;&#34;&#34;
        初始化欧几里得空间
        
        参数:
            dimension: 空间维数
        &#34;&#34;&#34;
        self.dimension = dimension
    
    def inner_product(self, x: np.ndarray, y: np.ndarray) -&gt; float:
        &#34;&#34;&#34;
        计算内积（点积）
        
        参数:
            x, y: 向量
        
        返回:
            内积 &lt;x, y&gt;
        &#34;&#34;&#34;
        self._check_vectors(x, y)
        return np.dot(x, y)
    
    def norm(self, x: np.ndarray, p: int = 2) -&gt; float:
        &#34;&#34;&#34;
        计算向量的范数
        
        参数:
            x: 向量
            p: 范数的阶数 (1: L1, 2: L2, np.inf: L∞)
        
        返回:
            ||x||_p
        &#34;&#34;&#34;
        self._check_dimension(x)
        return np.linalg.norm(x, ord=p)
    
    def distance(self, x: np.ndarray, y: np.ndarray) -&gt; float:
        &#34;&#34;&#34;
        计算欧氏距离
        
        参数:
            x, y: 向量
        
        返回:
            d(x, y) = ||x - y||
        &#34;&#34;&#34;
        self._check_vectors(x, y)
        return self.norm(x - y)
    
    def angle(self, x: np.ndarray, y: np.ndarray) -&gt; float:
        &#34;&#34;&#34;
        计算两个向量之间的夹角（弧度）
        
        使用公式: cos(θ) = &lt;x,y&gt; / (||x|| ||y||)
        
        参数:
            x, y: 向量
        
        返回:
            夹角（弧度）
        &#34;&#34;&#34;
        self._check_vectors(x, y)
        
        cos_angle = self.inner_product(x, y) / (self.norm(x) * self.norm(y))
        # 处理数值误差
        cos_angle = np.clip(cos_angle, -1.0, 1.0)
        
        return np.arccos(cos_angle)
    
    def cosine_similarity(self, x: np.ndarray, y: np.ndarray) -&gt; float:
        &#34;&#34;&#34;
        计算余弦相似度
        
        余弦相似度 = &lt;x,y&gt; / (||x|| ||y||)
        
        参数:
            x, y: 向量
        
        返回:
            余弦相似度 ∈ [-1, 1]
        &#34;&#34;&#34;
        self._check_vectors(x, y)
        
        norm_x = self.norm(x)
        norm_y = self.norm(y)
        
        if norm_x == 0 or norm_y == 0:
            return 0.0
        
        return self.inner_product(x, y) / (norm_x * norm_y)
    
    def projection(self, x: np.ndarray, y: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        计算 x 在 y 上的投影
        
        proj_y(x) = (&lt;x,y&gt; / &lt;y,y&gt;) * y
        
        参数:
            x: 被投影的向量
            y: 投影方向
        
        返回:
            投影向量
        &#34;&#34;&#34;
        self._check_vectors(x, y)
        
        return (self.inner_product(x, y) / self.inner_product(y, y)) * y
    
    def gram_schmidt(self, vectors: List[np.ndarray]) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        Gram-Schmidt 正交化过程
        
        将一组线性无关的向量转换为正交向量组
        
        参数:
            vectors: 向量列表
        
        返回:
            正交化后的向量列表
        &#34;&#34;&#34;
        orthogonal = []
        
        for v in vectors:
            # 减去在所有已正交化向量上的投影
            w = v.copy()
            for u in orthogonal:
                w -= self.projection(v, u)
            
            # 只有非零向量才加入
            if self.norm(w) &gt; 1e-10:
                orthogonal.append(w)
        
        return orthogonal
    
    def orthonormalize(self, vectors: List[np.ndarray]) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        正交归一化：Gram-Schmidt &#43; 归一化
        
        参数:
            vectors: 向量列表
        
        返回:
            标准正交基
        &#34;&#34;&#34;
        orthogonal = self.gram_schmidt(vectors)
        
        # 归一化
        orthonormal = [v / self.norm(v) for v in orthogonal]
        
        return orthonormal
    
    def _check_dimension(self, x: np.ndarray):
        &#34;&#34;&#34;检查向量维度&#34;&#34;&#34;
        if len(x) != self.dimension:
            raise ValueError(f&#34;向量维度应为 {self.dimension}, 得到 {len(x)}&#34;)
    
    def _check_vectors(self, x: np.ndarray, y: np.ndarray):
        &#34;&#34;&#34;检查两个向量的维度&#34;&#34;&#34;
        self._check_dimension(x)
        self._check_dimension(y)


# 机器学习应用示例
class KNearestNeighbors:
    &#34;&#34;&#34;
    K近邻算法：基于欧氏距离
    &#34;&#34;&#34;
    
    def __init__(self, k: int = 3):
        &#34;&#34;&#34;
        初始化KNN分类器
        
        参数:
            k: 近邻数量
        &#34;&#34;&#34;
        self.k = k
        self.X_train = None
        self.y_train = None
        self.euclidean_space = None
    
    def fit(self, X: np.ndarray, y: np.ndarray):
        &#34;&#34;&#34;
        训练模型（存储训练数据）
        
        参数:
            X: 训练特征 (n_samples, n_features)
            y: 训练标签 (n_samples,)
        &#34;&#34;&#34;
        self.X_train = X
        self.y_train = y
        self.euclidean_space = EuclideanSpace(X.shape[1])
    
    def predict(self, X: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        预测
        
        参数:
            X: 测试特征 (n_samples, n_features)
        
        返回:
            预测标签 (n_samples,)
        &#34;&#34;&#34;
        predictions = []
        
        for x in X:
            # 计算到所有训练样本的距离
            distances = [
                self.euclidean_space.distance(x, x_train)
                for x_train in self.X_train
            ]
            
            # 找到k个最近邻
            k_nearest_indices = np.argsort(distances)[:self.k]
            k_nearest_labels = self.y_train[k_nearest_indices]
            
            # 多数投票
            prediction = np.bincount(k_nearest_labels).argmax()
            predictions.append(prediction)
        
        return np.array(predictions)


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;欧几里得空间示例&#34;)
    print(&#34;=&#34; * 50)
    
    # 创建3维欧几里得空间
    E3 = EuclideanSpace(dimension=3)
    
    # 测试向量
    x = np.array([1.0, 2.0, 3.0])
    y = np.array([4.0, 5.0, 6.0])
    
    print(f&#34;向量 x = {x}&#34;)
    print(f&#34;向量 y = {y}&#34;)
    print(f&#34;\n内积 &lt;x, y&gt; = {E3.inner_product(x, y):.4f}&#34;)
    print(f&#34;||x|| = {E3.norm(x):.4f}&#34;)
    print(f&#34;||y|| = {E3.norm(y):.4f}&#34;)
    print(f&#34;距离 d(x, y) = {E3.distance(x, y):.4f}&#34;)
    print(f&#34;夹角 θ = {np.degrees(E3.angle(x, y)):.2f}°&#34;)
    print(f&#34;余弦相似度 = {E3.cosine_similarity(x, y):.4f}&#34;)
    
    # Gram-Schmidt 正交化示例
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;Gram-Schmidt 正交化&#34;)
    print(&#34;=&#34; * 50)
    
    v1 = np.array([1.0, 1.0, 0.0])
    v2 = np.array([1.0, 0.0, 1.0])
    v3 = np.array([0.0, 1.0, 1.0])
    
    vectors = [v1, v2, v3]
    orthonormal_basis = E3.orthonormalize(vectors)
    
    print(&#34;原始向量:&#34;)
    for i, v in enumerate(vectors):
        print(f&#34;  v{i&#43;1} = {v}&#34;)
    
    print(&#34;\n标准正交基:&#34;)
    for i, v in enumerate(orthonormal_basis):
        print(f&#34;  u{i&#43;1} = {v}&#34;)
        print(f&#34;  ||u{i&#43;1}|| = {E3.norm(v):.6f}&#34;)
    
    # 验证正交性
    print(&#34;\n正交性验证:&#34;)
    for i in range(len(orthonormal_basis)):
        for j in range(i&#43;1, len(orthonormal_basis)):
            dot_product = E3.inner_product(orthonormal_basis[i], orthonormal_basis[j])
            print(f&#34;  &lt;u{i&#43;1}, u{j&#43;1}&gt; = {dot_product:.10f}&#34;)
    
    # KNN 示例
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;K近邻分类示例（基于欧氏距离）&#34;)
    print(&#34;=&#34; * 50)
    
    # 生成示例数据
    np.random.seed(42)
    X_train = np.vstack([
        np.random.randn(50, 2) &#43; [0, 0],  # 类别0
        np.random.randn(50, 2) &#43; [3, 3],  # 类别1
    ])
    y_train = np.array([0]*50 &#43; [1]*50)
    
    # 训练KNN
    knn = KNearestNeighbors(k=5)
    knn.fit(X_train, y_train)
    
    # 测试
    X_test = np.array([[0, 0], [3, 3], [1.5, 1.5]])
    predictions = knn.predict(X_test)
    
    print(&#34;测试样本预测:&#34;)
    for i, (sample, pred) in enumerate(zip(X_test, predictions)):
        print(f&#34;  样本 {sample} → 类别 {pred}&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><hr><h2 id=5-线性无关-linear-independence>5. 线性无关 (Linear Independence)</h2><h3 id=数学概念-4>数学概念</h3><p><strong>线性无关</strong>是线性代数中的核心概念，描述向量组之间的独立性。</p><p><strong>定义</strong>：向量组 {v₁, v₂, &mldr;, vₖ} 线性无关，当且仅当方程</p>$$a_1v_1 + a_2v_2 + ... + a_kv_k = 0$$<p>仅在 a₁ = a₂ = &mldr; = aₖ = 0 时成立。</p><p><strong>等价条件</strong>：</p><ul><li>没有向量可以表示为其他向量的线性组合</li><li>从组中移除任何向量都会改变生成空间</li><li>矩阵的秩等于向量数量</li></ul><h3 id=在机器学习中的应用-4>在机器学习中的应用</h3><ul><li><strong>特征选择</strong>：去除线性相关的特征避免多重共线性</li><li><strong>主成分分析</strong>：寻找线性无关的主成分</li><li><strong>矩阵分解</strong>：确保分解的唯一性</li></ul><h3 id=python实现-4>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class LinearIndependence:
    &#34;&#34;&#34;线性无关性检验和相关算法&#34;&#34;&#34;
    
    @staticmethod
    def is_linearly_independent(vectors: List[np.ndarray], tol: float = 1e-10) -&gt; bool:
        &#34;&#34;&#34;
        检查向量组是否线性无关
        
        方法：将向量组成矩阵，检查秩是否等于向量数量
        
        参数:
            vectors: 向量列表
            tol: 数值容差
        
        返回:
            True 如果向量组线性无关
        &#34;&#34;&#34;
        if not vectors:
            return True
        
        # 构造矩阵（每列是一个向量）
        matrix = np.column_stack(vectors)
        
        # 计算秩
        rank = np.linalg.matrix_rank(matrix, tol=tol)
        
        # 如果秩等于向量数量，则线性无关
        return rank == len(vectors)
    
    @staticmethod
    def find_dependencies(vectors: List[np.ndarray], tol: float = 1e-10) -&gt; dict:
        &#34;&#34;&#34;
        找到线性相关关系
        
        参数:
            vectors: 向量列表
            tol: 数值容差
        
        返回:
            包含相关信息的字典
        &#34;&#34;&#34;
        if not vectors:
            return {&#39;is_independent&#39;: True, &#39;dependencies&#39;: []}
        
        matrix = np.column_stack(vectors)
        n_vectors = len(vectors)
        
        # 使用行化简
        # 首先做QR分解
        Q, R = np.linalg.qr(matrix)
        
        # 检查R的对角元素
        dependencies = []
        independent_indices = []
        
        for i in range(min(R.shape)):
            if abs(R[i, i]) &gt; tol:
                independent_indices.append(i)
            else:
                # 找到这个向量与前面向量的关系
                if i &gt; 0:
                    coeffs = R[:i, i] / np.diag(R[:i, :i])
                    dependencies.append({
                        &#39;dependent_index&#39;: i,
                        &#39;independent_indices&#39;: independent_indices.copy(),
                        &#39;coefficients&#39;: coeffs
                    })
        
        return {
            &#39;is_independent&#39;: len(dependencies) == 0,
            &#39;rank&#39;: len(independent_indices),
            &#39;independent_indices&#39;: independent_indices,
            &#39;dependencies&#39;: dependencies
        }
    
    @staticmethod
    def extract_independent_subset(vectors: List[np.ndarray], tol: float = 1e-10) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        提取最大线性无关子集
        
        参数:
            vectors: 向量列表
            tol: 数值容差
        
        返回:
            线性无关的向量子集
        &#34;&#34;&#34;
        if not vectors:
            return []
        
        independent = []
        
        for v in vectors:
            # 检查加入这个向量后是否仍然线性无关
            test_set = independent &#43; [v]
            if LinearIndependence.is_linearly_independent(test_set, tol):
                independent.append(v)
        
        return independent
    
    @staticmethod
    def compute_coefficients(target: np.ndarray, basis: List[np.ndarray]) -&gt; Union[np.ndarray, None]:
        &#34;&#34;&#34;
        如果 target 在 basis 的生成空间中，计算其系数
        
        参数:
            target: 目标向量
            basis: 基向量列表
        
        返回:
            系数数组，如果不在生成空间中则返回 None
        &#34;&#34;&#34;
        if not basis:
            return None
        
        # 构造矩阵方程 basis_matrix @ coeffs = target
        basis_matrix = np.column_stack(basis)
        
        try:
            # 使用最小二乘求解
            coeffs, residuals, rank, s = np.linalg.lstsq(basis_matrix, target, rcond=None)
            
            # 检查是否有精确解
            reconstruction = basis_matrix @ coeffs
            if np.allclose(reconstruction, target, atol=1e-10):
                return coeffs
            else:
                return None
        except np.linalg.LinAlgError:
            return None


# 多重共线性检测（机器学习应用）
class MulticollinearityDetector:
    &#34;&#34;&#34;
    检测特征之间的多重共线性
    多重共线性会导致线性回归不稳定
    &#34;&#34;&#34;
    
    @staticmethod
    def compute_vif(X: np.ndarray, feature_idx: int) -&gt; float:
        &#34;&#34;&#34;
        计算方差膨胀因子 (Variance Inflation Factor, VIF)
        
        VIF_i = 1 / (1 - R²_i)
        其中 R²_i 是用其他特征预测第 i 个特征的决定系数
        
        VIF &gt; 10 表示严重多重共线性
        
        参数:
            X: 特征矩阵 (n_samples, n_features)
            feature_idx: 要计算VIF的特征索引
        
        返回:
            VIF值
        &#34;&#34;&#34;
        n_features = X.shape[1]
        
        # 选择其他特征作为自变量
        other_features = [i for i in range(n_features) if i != feature_idx]
        X_other = X[:, other_features]
        y = X[:, feature_idx]
        
        # 使用其他特征预测该特征
        # 计算 R²
        X_other_with_bias = np.column_stack([np.ones(len(X_other)), X_other])
        
        try:
            theta = np.linalg.inv(X_other_with_bias.T @ X_other_with_bias) @ X_other_with_bias.T @ y
            y_pred = X_other_with_bias @ theta
            
            # 计算 R²
            ss_res = np.sum((y - y_pred) ** 2)
            ss_tot = np.sum((y - np.mean(y)) ** 2)
            r_squared = 1 - (ss_res / ss_tot)
            
            # 计算 VIF
            if r_squared &gt;= 0.9999:  # 防止除零
                return float(&#39;inf&#39;)
            
            vif = 1 / (1 - r_squared)
            return vif
            
        except np.linalg.LinAlgError:
            return float(&#39;inf&#39;)
    
    @staticmethod
    def detect_multicollinearity(X: np.ndarray, threshold: float = 10.0) -&gt; dict:
        &#34;&#34;&#34;
        检测所有特征的多重共线性
        
        参数:
            X: 特征矩阵
            threshold: VIF阈值
        
        返回:
            包含VIF和多重共线性诊断的字典
        &#34;&#34;&#34;
        n_features = X.shape[1]
        vifs = []
        
        for i in range(n_features):
            vif = MulticollinearityDetector.compute_vif(X, i)
            vifs.append(vif)
        
        problematic_features = [i for i, vif in enumerate(vifs) if vif &gt; threshold]
        
        return {
            &#39;vifs&#39;: vifs,
            &#39;problematic_features&#39;: problematic_features,
            &#39;has_multicollinearity&#39;: len(problematic_features) &gt; 0
        }


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;线性无关性检验&#34;)
    print(&#34;=&#34; * 50)
    
    # 示例1: 线性无关的向量组
    v1 = np.array([1.0, 0.0, 0.0])
    v2 = np.array([0.0, 1.0, 0.0])
    v3 = np.array([0.0, 0.0, 1.0])
    
    independent_vectors = [v1, v2, v3]
    
    is_indep = LinearIndependence.is_linearly_independent(independent_vectors)
    print(f&#34;向量组 1:&#34;)
    for i, v in enumerate(independent_vectors):
        print(f&#34;  v{i&#43;1} = {v}&#34;)
    print(f&#34;线性无关: {is_indep}&#34;)
    
    # 示例2: 线性相关的向量组
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;线性相关向量组&#34;)
    print(&#34;=&#34; * 50)
    
    u1 = np.array([1.0, 2.0, 3.0])
    u2 = np.array([2.0, 4.0, 6.0])  # u2 = 2*u1
    u3 = np.array([3.0, 6.0, 9.0])  # u3 = 3*u1
    
    dependent_vectors = [u1, u2, u3]
    
    print(f&#34;向量组 2:&#34;)
    for i, v in enumerate(dependent_vectors):
        print(f&#34;  u{i&#43;1} = {v}&#34;)
    
    dep_info = LinearIndependence.find_dependencies(dependent_vectors)
    print(f&#34;\n线性无关: {dep_info[&#39;is_independent&#39;]}&#34;)
    print(f&#34;秩: {dep_info[&#39;rank&#39;]}&#34;)
    print(f&#34;独立向量索引: {dep_info[&#39;independent_indices&#39;]}&#34;)
    
    # 提取独立子集
    independent_subset = LinearIndependence.extract_independent_subset(dependent_vectors)
    print(f&#34;\n最大线性无关子集大小: {len(independent_subset)}&#34;)
    
    # 示例3: 多重共线性检测
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;多重共线性检测（机器学习应用）&#34;)
    print(&#34;=&#34; * 50)
    
    # 创建有多重共线性的数据
    np.random.seed(42)
    n_samples = 100
    
    X1 = np.random.randn(n_samples)
    X2 = np.random.randn(n_samples)
    X3 = 2 * X1 &#43; 3 * X2 &#43; np.random.randn(n_samples) * 0.1  # X3 几乎是 X1 和 X2 的线性组合
    
    X = np.column_stack([X1, X2, X3])
    
    multicollinearity = MulticollinearityDetector.detect_multicollinearity(X)
    
    print(&#34;各特征的 VIF:&#34;)
    for i, vif in enumerate(multicollinearity[&#39;vifs&#39;]):
        print(f&#34;  特征 {i}: VIF = {vif:.2f}&#34;)
    
    if multicollinearity[&#39;has_multicollinearity&#39;]:
        print(f&#34;\n警告: 检测到多重共线性!&#34;)
        print(f&#34;问题特征索引: {multicollinearity[&#39;problematic_features&#39;]}&#34;)
    else:
        print(&#34;\n未检测到严重的多重共线性&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><p>继续第二部分&mldr;</p><hr><h2 id=6-基-basis>6. 基 (Basis)</h2><h3 id=数学概念-5>数学概念</h3><p><strong>基</strong>是向量空间中最重要的概念之一，它提供了空间的"坐标系统"。</p><p><strong>定义</strong>：向量空间 V 的一个基 B = {v₁, v₂, &mldr;, vₙ} 满足两个条件：</p><ol><li><strong>线性无关</strong>：基中的向量线性无关</li><li><strong>生成整个空间</strong>：Span(B) = V</li></ol><p><strong>重要性质</strong>：</p><ul><li>每个向量在给定基下有唯一的坐标表示</li><li>同一空间的所有基都有相同数量的向量</li><li>基的选择影响计算的复杂度和数值稳定性</li></ul><h3 id=在机器学习中的应用-5>在机器学习中的应用</h3><ul><li><strong>特征表示</strong>：选择合适的基可以简化问题</li><li><strong>PCA</strong>：找到数据方差最大的正交基</li><li><strong>傅里叶变换</strong>：从时域基转换到频域基</li><li><strong>小波变换</strong>：多尺度基表示</li></ul><h3 id=python实现-5>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class Basis:
    &#34;&#34;&#34;基的表示和操作&#34;&#34;&#34;
    
    def __init__(self, vectors: List[np.ndarray], name: str = &#34;B&#34;):
        &#34;&#34;&#34;
        初始化基
        
        参数:
            vectors: 基向量列表
            name: 基的名称
        &#34;&#34;&#34;
        # 验证是否线性无关
        if not LinearIndependence.is_linearly_independent(vectors):
            raise ValueError(&#34;基向量必须线性无关&#34;)
        
        self.vectors = [v.copy() for v in vectors]
        self.dimension = len(vectors)
        self.name = name
        
        # 构造基矩阵（每列是一个基向量）
        self.matrix = np.column_stack(vectors)
        
        # 计算逆矩阵（用于坐标变换）
        try:
            self.inverse_matrix = np.linalg.inv(self.matrix)
        except np.linalg.LinAlgError:
            self.inverse_matrix = None
    
    def to_coordinates(self, vector: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        将向量转换为该基下的坐标
        
        如果 v = c₁v₁ &#43; c₂v₂ &#43; ... &#43; cₙvₙ
        则返回 [c₁, c₂, ..., cₙ]
        
        参数:
            vector: 向量（标准基下）
        
        返回:
            该基下的坐标
        &#34;&#34;&#34;
        if self.inverse_matrix is None:
            raise ValueError(&#34;基不可逆&#34;)
        
        return self.inverse_matrix @ vector
    
    def from_coordinates(self, coordinates: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        从该基下的坐标转换为标准表示
        
        参数:
            coordinates: 该基下的坐标 [c₁, c₂, ..., cₙ]
        
        返回:
            向量（标准基下）
        &#34;&#34;&#34;
        return self.matrix @ coordinates
    
    def change_of_basis_matrix(self, other_basis: &#39;Basis&#39;) -&gt; np.ndarray:
        &#34;&#34;&#34;
        计算从this基到other基的变换矩阵
        
        参数:
            other_basis: 目标基
        
        返回:
            变换矩阵 P，使得 [v]_other = P [v]_this
        &#34;&#34;&#34;
        if self.inverse_matrix is None:
            raise ValueError(&#34;当前基不可逆&#34;)
        
        # P = B_other^(-1) @ B_this
        return other_basis.inverse_matrix @ self.matrix
    
    def is_orthogonal(self, tol: float = 1e-10) -&gt; bool:
        &#34;&#34;&#34;
        检查是否为正交基
        
        参数:
            tol: 数值容差
        
        返回:
            True 如果是正交基
        &#34;&#34;&#34;
        n = len(self.vectors)
        
        for i in range(n):
            for j in range(i&#43;1, n):
                dot_product = np.dot(self.vectors[i], self.vectors[j])
                if abs(dot_product) &gt; tol:
                    return False
        
        return True
    
    def is_orthonormal(self, tol: float = 1e-10) -&gt; bool:
        &#34;&#34;&#34;
        检查是否为标准正交基
        
        参数:
            tol: 数值容差
        
        返回:
            True 如果是标准正交基
        &#34;&#34;&#34;
        if not self.is_orthogonal(tol):
            return False
        
        # 检查每个向量的范数是否为1
        for v in self.vectors:
            if abs(np.linalg.norm(v) - 1.0) &gt; tol:
                return False
        
        return True
    
    def orthonormalize(self) -&gt; &#39;Basis&#39;:
        &#34;&#34;&#34;
        使用Gram-Schmidt过程将基正交归一化
        
        返回:
            新的标准正交基
        &#34;&#34;&#34;
        E3 = EuclideanSpace(self.dimension)
        orthonormal_vectors = E3.orthonormalize(self.vectors)
        
        return Basis(orthonormal_vectors, name=f&#34;{self.name}_orthonormal&#34;)


class PrincipalComponentAnalysis:
    &#34;&#34;&#34;
    主成分分析 (PCA) - 寻找数据的最优基
    
    PCA 找到使数据方差最大的正交基
    &#34;&#34;&#34;
    
    def __init__(self, n_components: int):
        &#34;&#34;&#34;
        初始化PCA
        
        参数:
            n_components: 主成分数量
        &#34;&#34;&#34;
        self.n_components = n_components
        self.components = None  # 主成分（新的基）
        self.mean = None
        self.explained_variance = None
        self.explained_variance_ratio = None
    
    def fit(self, X: np.ndarray):
        &#34;&#34;&#34;
        拟合PCA模型
        
        参数:
            X: 数据矩阵 (n_samples, n_features)
        &#34;&#34;&#34;
        # 中心化数据
        self.mean = np.mean(X, axis=0)
        X_centered = X - self.mean
        
        # 计算协方差矩阵
        cov_matrix = (X_centered.T @ X_centered) / (len(X) - 1)
        
        # 特征值分解
        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
        
        # 按特征值降序排序
        idx = np.argsort(eigenvalues)[::-1]
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]
        
        # 选择前n_components个主成分
        self.components = eigenvectors[:, :self.n_components].T
        self.explained_variance = eigenvalues[:self.n_components]
        self.explained_variance_ratio = self.explained_variance / np.sum(eigenvalues)
    
    def transform(self, X: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        将数据转换到主成分空间
        
        参数:
            X: 数据矩阵 (n_samples, n_features)
        
        返回:
            转换后的数据 (n_samples, n_components)
        &#34;&#34;&#34;
        if self.components is None:
            raise ValueError(&#34;模型尚未拟合&#34;)
        
        X_centered = X - self.mean
        return X_centered @ self.components.T
    
    def inverse_transform(self, X_transformed: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;
        从主成分空间转换回原始空间
        
        参数:
            X_transformed: 主成分空间的数据 (n_samples, n_components)
        
        返回:
            原始空间的近似重构 (n_samples, n_features)
        &#34;&#34;&#34;
        if self.components is None:
            raise ValueError(&#34;模型尚未拟合&#34;)
        
        return X_transformed @ self.components &#43; self.mean


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;基的操作示例&#34;)
    print(&#34;=&#34; * 50)
    
    # 示例1: 标准基
    e1 = np.array([1.0, 0.0, 0.0])
    e2 = np.array([0.0, 1.0, 0.0])
    e3 = np.array([0.0, 0.0, 1.0])
    
    standard_basis = Basis([e1, e2, e3], name=&#34;Standard&#34;)
    
    print(&#34;标准基:&#34;)
    for i, v in enumerate(standard_basis.vectors):
        print(f&#34;  e{i&#43;1} = {v}&#34;)
    
    print(f&#34;是否正交: {standard_basis.is_orthogonal()}&#34;)
    print(f&#34;是否标准正交: {standard_basis.is_orthonormal()}&#34;)
    
    # 示例2: 自定义基和坐标变换
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;坐标变换&#34;)
    print(&#34;=&#34; * 50)
    
    # 定义一个新基
    b1 = np.array([1.0, 1.0, 0.0])
    b2 = np.array([1.0, 0.0, 1.0])
    b3 = np.array([0.0, 1.0, 1.0])
    
    custom_basis = Basis([b1, b2, b3], name=&#34;Custom&#34;)
    
    # 测试向量
    v = np.array([3.0, 4.0, 5.0])
    
    print(f&#34;向量 v（标准基）= {v}&#34;)
    
    # 转换到自定义基
    coords_custom = custom_basis.to_coordinates(v)
    print(f&#34;v 在自定义基下的坐标 = {coords_custom}&#34;)
    
    # 验证：从坐标转换回来
    v_reconstructed = custom_basis.from_coordinates(coords_custom)
    print(f&#34;重构的 v = {v_reconstructed}&#34;)
    print(f&#34;重构误差 = {np.linalg.norm(v - v_reconstructed):.10f}&#34;)
    
    # 基变换矩阵
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;基变换&#34;)
    print(&#34;=&#34; * 50)
    
    P = custom_basis.change_of_basis_matrix(standard_basis)
    print(&#34;从自定义基到标准基的变换矩阵 P:&#34;)
    print(P)
    
    # 示例3: 正交化
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;基的正交化&#34;)
    print(&#34;=&#34; * 50)
    
    orthonormal_basis = custom_basis.orthonormalize()
    
    print(&#34;正交归一化后的基:&#34;)
    for i, v in enumerate(orthonormal_basis.vectors):
        print(f&#34;  u{i&#43;1} = {v}&#34;)
        print(f&#34;  ||u{i&#43;1}|| = {np.linalg.norm(v):.6f}&#34;)
    
    print(f&#34;\n是否标准正交: {orthonormal_basis.is_orthonormal()}&#34;)
    
    # 示例4: PCA（找到数据的最优基）
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;主成分分析 (PCA) - 数据驱动的基选择&#34;)
    print(&#34;=&#34; * 50)
    
    # 生成示例数据（椭圆分布）
    np.random.seed(42)
    n_samples = 300
    
    # 在主轴方向生成数据
    data_pca = np.random.randn(n_samples, 2)
    data_pca[:, 0] *= 3  # 第一个方向方差更大
    data_pca[:, 1] *= 1
    
    # 旋转数据
    theta = np.pi / 4
    rotation_matrix = np.array([
        [np.cos(theta), -np.sin(theta)],
        [np.sin(theta), np.cos(theta)]
    ])
    data_pca = data_pca @ rotation_matrix.T
    
    # 应用PCA
    pca = PrincipalComponentAnalysis(n_components=2)
    pca.fit(data_pca)
    
    print(&#34;主成分（新的基向量）:&#34;)
    for i, component in enumerate(pca.components):
        print(f&#34;  PC{i&#43;1} = {component}&#34;)
    
    print(f&#34;\n解释方差比: {pca.explained_variance_ratio}&#34;)
    print(f&#34;累积解释方差比: {np.cumsum(pca.explained_variance_ratio)}&#34;)
    
    # 转换数据
    data_transformed = pca.transform(data_pca)
    print(f&#34;\n原始数据形状: {data_pca.shape}&#34;)
    print(f&#34;转换后数据形状: {data_transformed.shape}&#34;)
    
    # 重构
    data_reconstructed = pca.inverse_transform(data_transformed)
    reconstruction_error = np.mean(np.linalg.norm(data_pca - data_reconstructed, axis=1))
    print(f&#34;重构误差: {reconstruction_error:.10f}&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><hr><h2 id=7-维数-dimension>7. 维数 (Dimension)</h2><h3 id=数学概念-6>数学概念</h3><p><strong>维数</strong>是向量空间最基本的不变量，描述空间的"自由度"。</p><p><strong>定义</strong>：如果向量空间 V 有一个有限基，则所有基的向量个数相同，这个数称为 V 的维数，记作 dim(V)。</p><p><strong>重要定理</strong>：</p><ol><li><strong>维数定理</strong>：所有基的大小相同</li><li><strong>秩-零化度定理</strong>：对于线性变换 T: V → W，
dim(V) = rank(T) + nullity(T)</li></ol><h3 id=在机器学习中的应用-6>在机器学习中的应用</h3><ul><li><strong>维度灾难</strong>：高维空间中数据稀疏</li><li><strong>降维</strong>：PCA, t-SNE 等减少维数</li><li><strong>嵌入</strong>：Word2Vec 将词映射到低维空间</li><li><strong>流形学习</strong>：发现数据的内在维度</li></ul><h3 id=python实现-6>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class DimensionAnalysis:
    &#34;&#34;&#34;维数分析和相关概念&#34;&#34;&#34;
    
    @staticmethod
    def compute_dimension(vectors: List[np.ndarray]) -&gt; int:
        &#34;&#34;&#34;
        计算向量组生成空间的维数
        
        维数 = 秩 = 最大线性无关子集的大小
        
        参数:
            vectors: 向量列表
        
        返回:
            维数
        &#34;&#34;&#34;
        if not vectors:
            return 0
        
        matrix = np.column_stack(vectors)
        return np.linalg.matrix_rank(matrix)
    
    @staticmethod
    def intrinsic_dimension_mle(X: np.ndarray, k: int = 10) -&gt; float:
        &#34;&#34;&#34;
        使用最大似然估计估计数据的内在维度
        
        基于局部距离的方法
        
        参数:
            X: 数据矩阵 (n_samples, n_features)
            k: 近邻数量
        
        返回:
            估计的内在维度
        &#34;&#34;&#34;
        from scipy.spatial.distance import cdist
        
        n_samples = len(X)
        
        # 计算距离矩阵
        distances = cdist(X, X)
        
        # 对每个点，找到k个最近邻
        dimensions = []
        
        for i in range(n_samples):
            # 获取第i个点到其他点的距离
            dists = distances[i]
            
            # 排序并选择最近的k&#43;1个点（包括自己）
            nearest_indices = np.argsort(dists)[1:k&#43;2]  # 跳过自己
            nearest_dists = dists[nearest_indices]
            
            # 使用MLE估计局部维度
            # d ≈ (k-1) / sum(log(r_k / r_i))
            r_k = nearest_dists[-1]
            
            if r_k &gt; 1e-10:
                log_ratios = np.log(r_k / nearest_dists[:-1])
                local_dim = (k - 1) / np.sum(log_ratios)
                dimensions.append(local_dim)
        
        return np.median(dimensions)


class DimensionalityCurse:
    &#34;&#34;&#34;
    维度灾难的演示
    &#34;&#34;&#34;
    
    @staticmethod
    def volume_of_unit_sphere(dimension: int) -&gt; float:
        &#34;&#34;&#34;
        计算单位球的体积
        
        V_d = π^(d/2) / Γ(d/2 &#43; 1)
        
        参数:
            dimension: 维数
        
        返回:
            单位球体积
        &#34;&#34;&#34;
        from scipy.special import gamma
        
        return np.pi ** (dimension / 2) / gamma(dimension / 2 &#43; 1)
    
    @staticmethod
    def sample_density(n_samples: int, dimension: int) -&gt; float:
        &#34;&#34;&#34;
        计算给定样本数和维度下的样本密度
        
        参数:
            n_samples: 样本数量
            dimension: 空间维数
        
        返回:
            样本密度（样本/体积）
        &#34;&#34;&#34;
        # 假设数据在单位超立方体中
        volume = 1.0  # 单位超立方体体积总是1
        
        return n_samples / volume
    
    @staticmethod
    def nearest_neighbor_distance(n_samples: int, dimension: int) -&gt; float:
        &#34;&#34;&#34;
        估计最近邻的平均距离
        
        在高维空间中，最近邻距离增加
        
        参数:
            n_samples: 样本数量
            dimension: 空间维数
        
        返回:
            估计的最近邻距离
        &#34;&#34;&#34;
        # 简化估计：d ∝ (V/n)^(1/d)
        # 其中 V 是体积，n 是样本数
        
        return (1.0 / n_samples) ** (1.0 / dimension)


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;维数计算&#34;)
    print(&#34;=&#34; * 50)
    
    # 示例1: 计算生成空间的维数
    v1 = np.array([1, 0, 0, 0])
    v2 = np.array([0, 1, 0, 0])
    v3 = np.array([1, 1, 0, 0])  # 线性相关
    v4 = np.array([0, 0, 1, 0])
    
    vectors = [v1, v2, v3, v4]
    dim = DimensionAnalysis.compute_dimension(vectors)
    
    print(f&#34;向量数量: {len(vectors)}&#34;)
    print(f&#34;生成空间的维数: {dim}&#34;)
    
    # 示例2: 内在维度估计
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;内在维度估计&#34;)
    print(&#34;=&#34; * 50)
    
    # 生成嵌入在高维空间中的低维数据
    np.random.seed(42)
    n_samples = 500
    
    # 真实的2D数据
    t = np.random.rand(n_samples) * 2 * np.pi
    true_2d = np.column_stack([np.cos(t), np.sin(t)])
    
    # 嵌入到10D空间
    embedding_matrix = np.random.randn(2, 10)
    embedded_data = true_2d @ embedding_matrix
    
    print(f&#34;嵌入空间维数: {embedded_data.shape[1]}&#34;)
    
    estimated_dim = DimensionAnalysis.intrinsic_dimension_mle(embedded_data, k=15)
    print(f&#34;估计的内在维度: {estimated_dim:.2f}&#34;)
    print(f&#34;真实的内在维度: 2&#34;)
    
    # 示例3: 维度灾难
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;维度灾难演示&#34;)
    print(&#34;=&#34; * 50)
    
    n_samples = 1000
    dimensions = [2, 5, 10, 20, 50, 100]
    
    print(f&#34;固定样本数: {n_samples}\n&#34;)
    print(f&#34;{&#39;维数&#39;:&gt;6} | {&#39;单位球体积&#39;:&gt;15} | {&#39;最近邻距离&#39;:&gt;15}&#34;)
    print(&#34;-&#34; * 50)
    
    for d in dimensions:
        volume = DimensionalityCurse.volume_of_unit_sphere(d)
        nn_dist = DimensionalityCurse.nearest_neighbor_distance(n_samples, d)
        
        print(f&#34;{d:6d} | {volume:15.6e} | {nn_dist:15.6f}&#34;)
    
    print(&#34;\n观察:&#34;)
    print(&#34;1. 单位球体积先增后减（高维时趋近于0）&#34;)
    print(&#34;2. 最近邻距离随维度增加而增大&#34;)
    print(&#34;3. 高维空间中数据变得稀疏&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><hr><h2 id=8-标准基-standard-basis>8. 标准基 (Standard Basis)</h2><h3 id=数学概念-7>数学概念</h3><p><strong>标准基</strong>是 Fⁿ 中最自然、最常用的基。</p><p><strong>定义</strong>：对于 n 维坐标空间，标准基是：</p>$$e_1 = (1, 0, ..., 0), e_2 = (0, 1, ..., 0), ..., e_n = (0, 0, ..., 1)$$<p><strong>性质</strong>：</p><ul><li>标准正交基</li><li>坐标表示最简单</li><li>计算效率最高</li></ul><h3 id=python实现-7>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class StandardBasis:
    &#34;&#34;&#34;标准基的实现和应用&#34;&#34;&#34;
    
    def __init__(self, dimension: int):
        &#34;&#34;&#34;
        创建标准基
        
        参数:
            dimension: 维数
        &#34;&#34;&#34;
        self.dimension = dimension
        self.vectors = self._create_standard_basis()
        self.basis = Basis(self.vectors, name=&#34;Standard&#34;)
    
    def _create_standard_basis(self) -&gt; List[np.ndarray]:
        &#34;&#34;&#34;
        创建标准基向量
        
        返回:
            标准基向量列表
        &#34;&#34;&#34;
        basis_vectors = []
        
        for i in range(self.dimension):
            e = np.zeros(self.dimension)
            e[i] = 1.0
            basis_vectors.append(e)
        
        return basis_vectors
    
    def get_vector(self, index: int) -&gt; np.ndarray:
        &#34;&#34;&#34;
        获取第 i 个标准基向量
        
        参数:
            index: 索引（从0开始）
        
        返回:
            第 i 个标准基向量
        &#34;&#34;&#34;
        if index &lt; 0 or index &gt;= self.dimension:
            raise IndexError(f&#34;索引应在 [0, {self.dimension}) 范围内&#34;)
        
        return self.vectors[index].copy()


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;标准基&#34;)
    print(&#34;=&#34; * 50)
    
    # 创建3维标准基
    std_basis_3d = StandardBasis(dimension=3)
    
    print(&#34;3维标准基:&#34;)
    for i in range(std_basis_3d.dimension):
        e = std_basis_3d.get_vector(i)
        print(f&#34;  e_{i&#43;1} = {e}&#34;)
    
    # 验证性质
    print(f&#34;\n是否标准正交: {std_basis_3d.basis.is_orthonormal()}&#34;)
    
    # 任意向量在标准基下的坐标就是其分量
    v = np.array([3.0, 4.0, 5.0])
    coords = std_basis_3d.basis.to_coordinates(v)
    
    print(f&#34;\n向量 v = {v}&#34;)
    print(f&#34;在标准基下的坐标 = {coords}&#34;)
    print(f&#34;坐标与分量相同: {np.allclose(v, coords)}&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div><hr><h2 id=9-范数-norm>9. 范数 (Norm)</h2><h3 id=数学概念-8>数学概念</h3><p><strong>范数</strong>是向量"长度"的推广，用于度量向量的大小。</p><p><strong>定义</strong>：函数 ∥·∥: V → ℝ 称为范数，如果满足：</p><ol><li><strong>正定性</strong>：∥v∥ ≥ 0，且 ∥v∥ = 0 ⟺ v = 0</li><li><strong>齐次性</strong>：∥αv∥ = |α|∥v∥</li><li><strong>三角不等式</strong>：∥u + v∥ ≤ ∥u∥ + ∥v∥</li></ol><p><strong>常用范数</strong>：</p><ul><li><strong>L¹ 范数</strong>（曼哈顿距离）：∥x∥₁ = Σ|xᵢ|</li><li><strong>L² 范数</strong>（欧氏距离）：∥x∥₂ = √(Σxᵢ²)</li><li><strong>L∞ 范数</strong>（最大范数）：∥x∥∞ = max|xᵢ|</li><li><strong>Lᵖ 范数</strong>：∥x∥ₚ = (Σ|xᵢ|ᵖ)^(1/p)</li></ul><h3 id=在机器学习中的应用-7>在机器学习中的应用</h3><ul><li><strong>正则化</strong>：L1正则化（Lasso）、L2正则化（Ridge）</li><li><strong>距离度量</strong>：不同范数对应不同的距离概念</li><li><strong>优化</strong>：梯度的范数用于判断收敛</li><li><strong>归一化</strong>：特征缩放</li></ul><h3 id=python实现-8>Python实现</h3><div class=code-playground data-language=python><div><pre><code class=language-python>class NormOperations:
    &#34;&#34;&#34;各种范数的计算和应用&#34;&#34;&#34;
    
    @staticmethod
    def lp_norm(x: np.ndarray, p: float = 2) -&gt; float:
        &#34;&#34;&#34;
        计算 Lp 范数
        
        ||x||_p = (Σ|x_i|^p)^(1/p)
        
        参数:
            x: 向量
            p: 范数的阶数
        
        返回:
            Lp 范数
        &#34;&#34;&#34;
        if p == np.inf:
            return np.max(np.abs(x))
        elif p == 1:
            return np.sum(np.abs(x))
        elif p == 2:
            return np.sqrt(np.sum(x ** 2))
        else:
            return np.sum(np.abs(x) ** p) ** (1.0 / p)
    
    @staticmethod
    def normalize(x: np.ndarray, p: float = 2) -&gt; np.ndarray:
        &#34;&#34;&#34;
        归一化向量（使其范数为1）
        
        参数:
            x: 向量
            p: 使用的范数
        
        返回:
            归一化后的向量
        &#34;&#34;&#34;
        norm = NormOperations.lp_norm(x, p)
        
        if norm &lt; 1e-10:
            return x
        
        return x / norm
    
    @staticmethod
    def unit_ball_visualization_2d(p_values: List[float] = [0.5, 1, 2, np.inf]):
        &#34;&#34;&#34;
        可视化不同范数的单位球（2D情况）
        
        参数:
            p_values: 要可视化的p值列表
        &#34;&#34;&#34;
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 12))
        axes = axes.ravel()
        
        theta = np.linspace(0, 2*np.pi, 1000)
        
        for idx, p in enumerate(p_values):
            ax = axes[idx]
            
            if p == np.inf:
                # L∞ 范数：正方形
                x = np.array([1, 1, -1, -1, 1])
                y = np.array([1, -1, -1, 1, 1])
            else:
                # 参数方程
                x = np.sign(np.cos(theta)) * np.abs(np.cos(theta)) ** (2/p)
                y = np.sign(np.sin(theta)) * np.abs(np.sin(theta)) ** (2/p)
            
            ax.plot(x, y, &#39;b-&#39;, linewidth=2)
            ax.grid(True, alpha=0.3)
            ax.set_aspect(&#39;equal&#39;)
            ax.set_xlim(-1.5, 1.5)
            ax.set_ylim(-1.5, 1.5)
            ax.set_title(f&#39;L{p} Norm Unit Ball&#39;, fontsize=14)
            ax.axhline(y=0, color=&#39;k&#39;, linewidth=0.5)
            ax.axvline(x=0, color=&#39;k&#39;, linewidth=0.5)
        
        plt.tight_layout()
        return fig


class RegularizedLinearRegression:
    &#34;&#34;&#34;
    带正则化的线性回归
    
    损失函数：L(w) = ||Xw - y||² &#43; λ||w||ₚ
    &#34;&#34;&#34;
    
    def __init__(self, regularization: str = &#39;l2&#39;, lambda_reg: float = 0.1):
        &#34;&#34;&#34;
        初始化正则化线性回归
        
        参数:
            regularization: &#39;l1&#39; (Lasso), &#39;l2&#39; (Ridge), 或 &#39;none&#39;
            lambda_reg: 正则化强度
        &#34;&#34;&#34;
        self.regularization = regularization
        self.lambda_reg = lambda_reg
        self.weights = None
        self.bias = None
    
    def fit(self, X: np.ndarray, y: np.ndarray, max_iter: int = 1000, lr: float = 0.01):
        &#34;&#34;&#34;
        使用梯度下降训练模型
        
        参数:
            X: 特征矩阵 (n_samples, n_features)
            y: 目标值 (n_samples,)
            max_iter: 最大迭代次数
            lr: 学习率
        &#34;&#34;&#34;
        n_samples, n_features = X.shape
        
        # 初始化权重
        self.weights = np.zeros(n_features)
        self.bias = 0.0
        
        for iteration in range(max_iter):
            # 预测
            y_pred = X @ self.weights &#43; self.bias
            
            # 计算梯度
            error = y_pred - y
            grad_w = (2/n_samples) * (X.T @ error)
            grad_b = (2/n_samples) * np.sum(error)
            
            # 添加正则化项的梯度
            if self.regularization == &#39;l2&#39;:
                grad_w &#43;= 2 * self.lambda_reg * self.weights
            elif self.regularization == &#39;l1&#39;:
                grad_w &#43;= self.lambda_reg * np.sign(self.weights)
            
            # 更新参数
            self.weights -= lr * grad_w
            self.bias -= lr * grad_b
            
            # 每100次迭代打印损失
            if iteration % 100 == 0:
                loss = self._compute_loss(X, y)
                print(f&#34;Iteration {iteration}: Loss = {loss:.4f}&#34;)
    
    def _compute_loss(self, X: np.ndarray, y: np.ndarray) -&gt; float:
        &#34;&#34;&#34;计算损失函数&#34;&#34;&#34;
        y_pred = X @ self.weights &#43; self.bias
        mse = np.mean((y - y_pred) ** 2)
        
        if self.regularization == &#39;l2&#39;:
            reg_term = self.lambda_reg * np.sum(self.weights ** 2)
        elif self.regularization == &#39;l1&#39;:
            reg_term = self.lambda_reg * np.sum(np.abs(self.weights))
        else:
            reg_term = 0
        
        return mse &#43; reg_term
    
    def predict(self, X: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;预测&#34;&#34;&#34;
        return X @ self.weights &#43; self.bias


# 示例使用
if __name__ == &#34;__main__&#34;:
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;范数计算&#34;)
    print(&#34;=&#34; * 50)
    
    # 示例向量
    x = np.array([3, 4, 0])
    
    print(f&#34;向量 x = {x}\n&#34;)
    
    # 计算不同范数
    for p in [1, 2, 3, np.inf]:
        norm_value = NormOperations.lp_norm(x, p)
        print(f&#34;L{p} 范数: ||x||_{p} = {norm_value:.4f}&#34;)
    
    # 归一化
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;向量归一化&#34;)
    print(&#34;=&#34; * 50)
    
    for p in [1, 2, np.inf]:
        x_normalized = NormOperations.normalize(x, p)
        norm_check = NormOperations.lp_norm(x_normalized, p)
        
        print(f&#34;\nL{p} 归一化:&#34;)
        print(f&#34;  归一化向量: {x_normalized}&#34;)
        print(f&#34;  验证范数 = {norm_check:.10f}&#34;)
    
    # 正则化线性回归示例
    print(&#34;\n&#34; &#43; &#34;=&#34; * 50)
    print(&#34;正则化线性回归（范数应用）&#34;)
    print(&#34;=&#34; * 50)
    
    # 生成数据
    np.random.seed(42)
    n_samples, n_features = 100, 5
    X_train = np.random.randn(n_samples, n_features)
    true_weights = np.array([2, -1, 0, 0, 0.5])  # 稀疏权重
    y_train = X_train @ true_weights &#43; np.random.randn(n_samples) * 0.1
    
    print(f&#34;真实权重: {true_weights}\n&#34;)
    
    # L2 正则化 (Ridge)
    print(&#34;L2 正则化 (Ridge):&#34;)
    ridge = RegularizedLinearRegression(regularization=&#39;l2&#39;, lambda_reg=0.1)
    ridge.fit(X_train, y_train, max_iter=500, lr=0.01)
    print(f&#34;学习的权重: {ridge.weights}&#34;)
    print(f&#34;||w||_2 = {NormOperations.lp_norm(ridge.weights, 2):.4f}\n&#34;)
    
    # L1 正则化 (Lasso)
    print(&#34;L1 正则化 (Lasso):&#34;)
    lasso = RegularizedLinearRegression(regularization=&#39;l1&#39;, lambda_reg=0.1)
    lasso.fit(X_train, y_train, max_iter=500, lr=0.01)
    print(f&#34;学习的权重: {lasso.weights}&#34;)
    print(f&#34;||w||_1 = {NormOperations.lp_norm(lasso.weights, 1):.4f}&#34;)
    print(f&#34;稀疏性（接近0的权重数）: {np.sum(np.abs(lasso.weights) &lt; 0.1)}&#34;)</code></pre></div><div class=controls><button class=run-button>
<span style=display:flex;align-items:center;gap:4px>运行
<svg t="1737473351499" class="icon" viewBox="0 0 1024 1024" p-id="11262" width="16" height="16"><path d="M512 96C282.624 96 96 282.624 96 512s186.624 416 416 416 416-186.624 416-416S741.376 96 512 96zm0 768c-194.08.0-352-157.92-352-352S317.92 160 512 160s352 157.92 352 352-157.92 352-352 352z" p-id="11263"/><path d="M466.816 324.96A32 32 0 00416 350.848v339.776a32 32 0 0050.816 25.856l233.6-169.888a32 32 0 000-51.776l-233.6-169.856z" p-id="11264"/></svg></span></button></div><div class=output style=display:none><pre class=output-content></pre></div></div></section><div class="flex flex-row items-center justify-center space-x-4"><div class=reward-container><button class=reward-button aria-expanded=false aria-controls=reward-pop>
支持作者</button><div id=reward-pop class="reward-popup hidden"><p class=reward-text>感谢支持！🍻</p><div class=qr-container><div class=reward-qr><img src=/images/payment/wechat.jpg alt=微信支付二维码 loading=lazy><p>微信</p></div><div class=reward-qr><img src=/images/payment/alipay.jpg alt=支付宝二维码 loading=lazy><p>支付宝</p></div></div></div></div><style>.reward-container{text-align:center;margin:2rem 0}.reward-button{padding:.5rem 1.25rem;background-color:#f44336;color:#fff;border:none;border-radius:1rem;cursor:pointer;transition:all .2s ease;font-size:1rem}.reward-button:hover{background-color:red;font-size:1rem;transform:translateY(-1px);box-shadow:0 2px 4px rgba(0,0,0,.2)}.reward-button:active{background-color:red;font-weight:700;font-size:.9rem;transform:translateY(-1px);box-shadow:0 2px 4px rgba(0,0,0,.2)}.reward-popup{margin-top:1.5rem;opacity:0;transform:translateY(-10px);transition:all .3s ease}.reward-popup.visible{opacity:1;transform:translateY(0)}.reward-text{margin-bottom:1rem;color:#333;font-size:1.1rem}.reward-text:is(.dark *){margin-bottom:1rem;color:#fff;font-size:1.1rem}.qr-container{display:flex;justify-content:center;gap:2rem;flex-wrap:wrap}.reward-qr{text-align:center}.reward-qr img{width:200px;padding:1rem;background-color:#fff;border-radius:.5rem;box-shadow:0 2px 8px rgba(0,0,0,.1);transition:transform .2s ease}.reward-qr img:hover{transform:scale(1.02)}.reward-qr p{margin:.5rem 0 0;color:#666;font-size:.95rem}.reward-qr p:is(.dark *){margin:.5rem 0 0;color:#fff;font-size:.95rem}.hidden{display:none}</style><script>const button=document.querySelector(".reward-button"),popup=document.getElementById("reward-pop");button.addEventListener("click",()=>{const e=button.getAttribute("aria-expanded")==="true";button.setAttribute("aria-expanded",!e),popup.classList.toggle("hidden"),setTimeout(()=>{popup.classList.toggle("visible")},10)})</script><style>.share-trigger-btn{padding:.5rem 1.25rem;background-color:#0053e0;color:#fff;border:none;border-radius:1rem;cursor:pointer;transition:all .2s ease;font-size:1rem;display:inline-flex;align-items:center}.share-trigger-btn:hover{transform:translateY(-2px);box-shadow:0 6px 20px rgba(225,123,123,.5)}.share-trigger-btn:active{transform:translateY(0)}.share-panel-overlay{position:fixed;top:0;left:0;right:0;bottom:0;background:rgba(0,0,0,.7);backdrop-filter:blur(8px);z-index:9999;display:flex;align-items:center;justify-content:center;opacity:0;visibility:hidden;transition:all .3s ease;padding:1rem}.share-panel-overlay.active{opacity:1;visibility:visible}.share-panel-container{background:#fff;border-radius:24px;max-width:480px;width:100%;max-height:90vh;overflow-y:auto;position:relative;box-shadow:0 25px 50px -12px rgba(0,0,0,.25);transform:scale(.9)translateY(20px);transition:all .3s cubic-bezier(.4,0,.2,1)}.share-panel-overlay.active .share-panel-container{transform:scale(1)translateY(0)}.share-panel-container::-webkit-scrollbar{width:6px}.share-panel-container::-webkit-scrollbar-track{background:#f1f5f9;border-radius:3px}.share-panel-container::-webkit-scrollbar-thumb{background:#cbd5e1;border-radius:3px}.share-panel-container::-webkit-scrollbar-thumb:hover{background:#94a3b8}.share-close-btn{position:absolute;top:1rem;right:1rem;width:40px;height:40px;border-radius:50%;background:rgba(255,255,255,.9);border:none;cursor:pointer;display:flex;align-items:center;justify-content:center;transition:all .2s;z-index:10;box-shadow:0 2px 8px rgba(0,0,0,.1)}.share-close-btn:hover{background:#fee2e2;color:#dc2626;transform:rotate(90deg)}.share-header{text-align:center;padding:3rem 2rem 2rem;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border-radius:24px 24px 0 0}.share-header-icon{width:64px;height:64px;margin:0 auto 1rem;background:rgba(255,255,255,.2);border-radius:20px;display:flex;align-items:center;justify-content:center;backdrop-filter:blur(10px)}.share-title{font-size:1.75rem;font-weight:700;margin:0 0 .5rem}.share-subtitle{font-size:.95rem;opacity:.9;margin:0}.share-content{padding:2rem}.share-section{margin-bottom:2rem}.share-section:last-child{margin-bottom:0}.section-label{display:flex;align-items:center;font-size:.875rem;font-weight:600;color:#64748b;margin-bottom:1rem;text-transform:uppercase;letter-spacing:.05em}.section-label svg{margin-right:.5rem;color:#667eea}.share-buttons-grid{display:grid;grid-template-columns:1fr;gap:.75rem}.share-btn{display:flex;align-items:center;padding:1rem;border:2px solid #f1f5f9;border-radius:12px;background:#fff;cursor:pointer;transition:all .2s;text-align:left}.share-btn:hover{border-color:initial;transform:translateX(4px);box-shadow:0 4px 12px rgba(0,0,0,.1)}.share-btn-icon{width:32px;height:32px;flex-shrink:0;margin-right:1rem}.share-btn-text{flex:1}.share-btn-name{display:block;font-weight:600;font-size:.95rem;margin-bottom:.125rem}.share-btn-desc{display:block;font-size:.8rem;color:#64748b}.share-btn-twitter{color:#1da1f2}.share-btn-linkedin{color:#0a66c2}.share-btn-weibo{color:#e6162d}.share-btn-wechat{color:#07c160}.share-btn-qq{color:#12b7f5}.share-btn-copy{color:#64748b}.share-card{display:flex;flex-direction:column}.card-decoration{height:6px;background:#fff}.card-image-wrapper{position:relative;height:180px;overflow:hidden;display:flex}.card-image{position:absolute;width:100%;height:auto;object-fit:cover;display:block;z-index:100;vertical-align:top;flex-shrink:0}.card-image-overlay{position:absolute;bottom:0;left:0;right:0;height:50%;background:linear-gradient(to top,rgba(0,0,0,.3),transparent)}.card-body{padding:1.5rem;background:#fff}.card-title{font-size:1.25rem;font-weight:700;color:#1e293b;margin:0 0 .75rem;line-height:1.4;display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden}.card-description{font-size:.875rem;color:#64748b;line-height:1.6;margin:0 0 1.25rem;display:-webkit-box;-webkit-line-clamp:3;-webkit-box-orient:vertical;overflow:hidden}.card-author{display:flex;align-items:center;margin-bottom:1rem;padding-bottom:1rem;border-bottom:1px solid #f1f5f9}.author-avatar-wrapper{position:relative;margin-right:.75rem}.author-avatar{width:48px;height:48px;border-radius:50%;object-fit:cover;border:3px solid #fff;box-shadow:0 2px 8px rgba(0,0,0,.1)}.author-avatar-ring{position:absolute;border-radius:50%;border:2px solid #667eea;opacity:0}@keyframes ring-pulse{0%,100%{opacity:0;transform:scale(1)}50%{opacity:.5;transform:scale(1.1)}}.author-info{flex:1}.author-name{font-weight:600;color:#1e293b;margin:0 0 .25rem;font-size:.95rem}.author-stats{display:flex;gap:1rem;font-size:.75rem;color:#64748b;margin:0}.stat-item{display:flex;align-items:center;gap:.25rem}.card-tags{display:flex;flex-wrap:wrap;gap:.5rem;margin-bottom:1rem}.tag-item{padding:.375rem .75rem;background:linear-gradient(135deg,#667eea15,#764ba215);color:#667eea;border-radius:20px;font-size:.75rem;font-weight:500;border:1px solid #667eea30}.tag-more{padding:.375rem .75rem;background:#f1f5f9;color:#64748b;border-radius:20px;font-size:.75rem}.contribution-section{margin-bottom:1rem;padding:1rem;background:#f8fafc;border-radius:12px}.contribution-title{display:flex;align-items:center;font-size:.875rem;font-weight:600;color:#475569;margin:0 0 .75rem}.contribution-title svg{margin-right:.5rem;color:#667eea}.contribution-grid{display:grid;grid-template-columns:repeat(auto-fill,10px);gap:3px;margin-bottom:.5rem}.contribution-cell{width:10px;height:10px;border-radius:2px;transition:all .2s;cursor:pointer}.contribution-cell:hover{transform:scale(1.5);z-index:10;box-shadow:0 0 0 2px rgba(102,126,234,.3)}.contribution-cell.level-0{background:#ebedf0}.contribution-cell.level-1{background:#c6e48b}.contribution-cell.level-2{background:#7bc96f}.contribution-cell.level-3{background:#239a3b}.contribution-cell.level-4{background:#196127}.contribution-legend{display:flex;align-items:center;justify-content:flex-end;gap:.5rem;font-size:.7rem;color:#64748b}.legend-cells{display:flex;gap:3px}.card-footer{display:flex;align-items:center;justify-content:space-between;padding-top:1rem;border-top:1px solid #f1f5f9}.footer-logo{display:flex;align-items:center;gap:.5rem}.footer-logo img{height:28px;width:auto}.footer-logo span{font-size:.875rem;color:#64748b;font-weight:500}#qrcodeSmall canvas{display:block}.card-actions{display:grid;grid-template-columns:1fr 1fr;gap:.75rem;margin-top:1rem}.action-btn{display:flex;align-items:center;justify-content:center;gap:.5rem;padding:.875rem 1rem;border-radius:12px;font-weight:600;font-size:.875rem;cursor:pointer;transition:all .2s;border:none}.action-btn-primary{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;box-shadow:0 4px 12px rgba(102,126,234,.3)}.action-btn-primary:hover{transform:translateY(-2px);box-shadow:0 6px 16px rgba(102,126,234,.4)}.action-btn-secondary{background:#fff;color:#667eea;border:2px solid #667eea}.action-btn-secondary:hover{background:#667eea;color:#fff}.stats-grid{display:grid;grid-template-columns:1fr 1fr;gap:1rem}.stat-card{background:linear-gradient(135deg,#f8fafc 0%,#f1f5f9 100%);padding:1.5rem;border-radius:12px;text-align:center;border:1px solid #e2e8f0}.stat-value{font-size:2rem;font-weight:700;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);-webkit-background-clip:text;-webkit-text-fill-color:transparent;margin-bottom:.5rem}.stat-label{font-size:.75rem;color:#64748b;font-weight:500}.share-toast{position:fixed;bottom:2rem;left:50%;transform:translateX(-50%)translateY(100px);background:#1e293b;color:#fff;padding:1rem 1.5rem;border-radius:12px;font-size:.875rem;font-weight:500;box-shadow:0 10px 25px rgba(0,0,0,.3);z-index:10000;opacity:0;transition:all .3s cubic-bezier(.4,0,.2,1)}.share-toast.show{opacity:1;transform:translateX(-50%)translateY(0)}@media(max-width:640px){.share-panel-container{max-width:100%;border-radius:24px 24px 0 0;max-height:95vh}.share-header{padding:2rem 1.5rem 1.5rem}.share-title{font-size:1.5rem}.share-content{padding:1.5rem}.card-actions{grid-template-columns:1fr}.contribution-grid{grid-template-columns:repeat(auto-fill,8px);gap:2px}.contribution-cell{width:8px;height:8px}}@media(prefers-color-scheme:dark){.share-panel-container{background:#1e293b}.card-body{background:#0f172a}.card-title{color:#f1f5f9}.card-description{color:#cbd5e1}.author-name{color:#f1f5f9}.share-btn{background:#334155;border-color:#475569}.stat-card{background:linear-gradient(135deg,#1e293b 0%,#334155 100%);border-color:#475569}}</style><button class=share-trigger-btn aria-label=分享文章>
<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8.684 13.342C8.886 12.938 9 12.482 9 12s-.114-.938-.316-1.342m0 2.684a3 3 0 110-2.684m0 2.684 6.632 3.316m-6.632-6 6.632-3.316m0 0a3 3 0 105.367-2.684 3 3 0 00-5.367 2.684zm0 9.316a3 3 0 105.368 2.684 3 3 0 00-5.368-2.684z"/></svg>
<span class=ml-2>分享</span></button><div class=share-panel-overlay id=sharePanel><div class=share-panel-container><button class=share-close-btn aria-label=关闭>
<svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button><div class=share-content><section class=share-section><h3 class=section-label><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"/></svg>
快速分享</h3><div class="grid grid-cols-3 gap-3 md:gap-4"><button class=share-btn-icon-only onclick='shareTo("twitter")' title=Twitter>
<img src=/icon/app/x.svg alt=Twitter class=share-btn-icon>
</button>
<button class=share-btn-icon-only onclick='shareTo("linkedin")' title=LinkedIn>
<img src=/icon/app/linkedin.svg alt=LinkedIn class=share-btn-icon>
</button>
<button class=share-btn-icon-only onclick='shareTo("weibo")' title=微博>
<img src=/icon/app/weibo.svg alt=微博 class=share-btn-icon>
</button>
<button class=share-btn-icon-only onclick='shareTo("wechat")' title=微信>
<img src=/icon/app/weixin.svg alt=微信 class=share-btn-icon>
</button>
<button class=share-btn-icon-only onclick='shareTo("qq")' title=QQ>
<img src=/icon/app/qq.svg alt=QQ class=share-btn-icon>
</button>
<button class=share-btn-icon-only onclick=copyLink() title=复制链接>
<img src=/icon/app/url.svg alt=URL class=share-btn-icon></button></div></section><section class=share-sectio><h3 class=section-label><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 21a4 4 0 01-4-4V5a2 2 0 012-2h4a2 2 0 012 2v12a4 4 0 01-4 4zm0 0h12a2 2 0 002-2v-4a2 2 0 00-2-2h-2.343M11 7.343l1.657-1.657a2 2 0 012.828.0l2.829 2.829a2 2 0 010 2.828l-8.486 8.485M7 17h.01"/></svg>
分享卡片</h3><div class="share-card border-2 rounded-lg" id=shareCard><div class="w-full h-48 md:h-64 lg:h-72 overflow-hidden bg-gray-100 flex items-center justify-center"><img src=https://cdn.pixabay.com/photo/2019/12/21/20/44/math-work-4711302_1280.jpg alt=人工智能中的数学基础 class="w-full h-full object-contain" loading=lazy></div><div class=card-body><h4 class=card-title>人工智能中的数学基础</h4><p class=card-description><h2 id=1-向量空间-vector-space>1. 向量空间 (Vector Space)</h2><h3 id=数学概念>数学概念</h3><p><strong>向量空间</strong>是线性代数的核心概念，它是一个满足特定运算规则的集合。</p><p><strong>定义要素</strong>：</p><ul><li><strong>域 F</strong>：通常是实数域 ℝ 或复数域 ℂ</li><li><strong>向量集合 V</strong>：非空集合</li><li><strong>两种运算</strong>：<ul><li>加法：V × V → V</li><li>数 …</li></ul></li></ul></p><div class=card-author><div class=author-avatar-wrapper><img src=https://simons.qzz.io/about/avatar.jpg alt=simons class=author-avatar loading=lazy><div class=author-avatar-ring></div></div><div class=author-info><p class=author-name>simons</p><p class=author-stats><span class=stat-item><svg class="w-3 h-3" fill="currentColor" viewBox="0 0 20 20"><path d="M9 2a1 1 0 000 2h2a1 1 0 100-2H9z"/><path fill-rule="evenodd" d="M4 5a2 2 0 012-2 3 3 0 003 3h2a3 3 0 003-3 2 2 0 012 2v11a2 2 0 01-2 2H6a2 2 0 01-2-2V5zm3 4a1 1 0 000 2h.01a1 1 0 100-2H7zm3 0a1 1 0 000 2h3a1 1 0 100-2h-3zm-3 4a1 1 0 100 2h.01a1 1 0 100-2H7zm3 0a1 1 0 100 2h3a1 1 0 100-2h-3z" clip-rule="evenodd"/></svg>
275 篇
</span><span class=stat-item><svg class="w-3 h-3" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm1-12A1 1 0 109 6v4a1 1 0 00.293.707l2.828 2.829a1 1 0 101.415-1.415L11 9.586V6z" clip-rule="evenodd"/></svg>
23 分钟</span></p></div></div><div class=card-tags><span class=tag-item>暂无</span></div><div class=contribution-section><h5 class=contribution-title><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/></svg>
创作活跃度</h5><div class=contribution-grid><div class="contribution-cell level-0" data-date=2025-11-04 data-count=0 title="2025-11-04: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-05 data-count=0 title="2025-11-05: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-06 data-count=0 title="2025-11-06: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-07 data-count=0 title="2025-11-07: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-08 data-count=0 title="2025-11-08: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-09 data-count=0 title="2025-11-09: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-10 data-count=0 title="2025-11-10: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-11 data-count=0 title="2025-11-11: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-12 data-count=0 title="2025-11-12: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-13 data-count=0 title="2025-11-13: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-14 data-count=0 title="2025-11-14: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-15 data-count=0 title="2025-11-15: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-16 data-count=0 title="2025-11-16: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-17 data-count=0 title="2025-11-17: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-18 data-count=0 title="2025-11-18: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-19 data-count=0 title="2025-11-19: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-20 data-count=0 title="2025-11-20: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-21 data-count=0 title="2025-11-21: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-22 data-count=0 title="2025-11-22: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-23 data-count=0 title="2025-11-23: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-24 data-count=0 title="2025-11-24: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-25 data-count=0 title="2025-11-25: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-26 data-count=0 title="2025-11-26: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-27 data-count=0 title="2025-11-27: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-28 data-count=0 title="2025-11-28: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-29 data-count=0 title="2025-11-29: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-11-30 data-count=0 title="2025-11-30: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-01 data-count=1 title="2025-12-01: 1 篇"></div><div class="contribution-cell level-0" data-date=2025-12-02 data-count=0 title="2025-12-02: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-03 data-count=0 title="2025-12-03: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-04 data-count=0 title="2025-12-04: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-05 data-count=0 title="2025-12-05: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-06 data-count=0 title="2025-12-06: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-07 data-count=0 title="2025-12-07: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-08 data-count=0 title="2025-12-08: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-09 data-count=0 title="2025-12-09: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-10 data-count=0 title="2025-12-10: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-11 data-count=0 title="2025-12-11: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-12 data-count=0 title="2025-12-12: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-13 data-count=0 title="2025-12-13: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-14 data-count=0 title="2025-12-14: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-15 data-count=0 title="2025-12-15: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-16 data-count=0 title="2025-12-16: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-17 data-count=0 title="2025-12-17: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-18 data-count=0 title="2025-12-18: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-19 data-count=0 title="2025-12-19: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-20 data-count=0 title="2025-12-20: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-21 data-count=0 title="2025-12-21: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-22 data-count=0 title="2025-12-22: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-23 data-count=0 title="2025-12-23: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-24 data-count=2 title="2025-12-24: 2 篇"></div><div class="contribution-cell level-0" data-date=2025-12-25 data-count=0 title="2025-12-25: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-26 data-count=0 title="2025-12-26: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-27 data-count=0 title="2025-12-27: 0 篇"></div><div class="contribution-cell level-1" data-date=2025-12-28 data-count=3 title="2025-12-28: 3 篇"></div><div class="contribution-cell level-0" data-date=2025-12-29 data-count=0 title="2025-12-29: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-30 data-count=0 title="2025-12-30: 0 篇"></div><div class="contribution-cell level-0" data-date=2025-12-31 data-count=0 title="2025-12-31: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-01 data-count=0 title="2026-01-01: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-02 data-count=0 title="2026-01-02: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-03 data-count=0 title="2026-01-03: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-04 data-count=0 title="2026-01-04: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-05 data-count=1 title="2026-01-05: 1 篇"></div><div class="contribution-cell level-0" data-date=2026-01-06 data-count=0 title="2026-01-06: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-07 data-count=0 title="2026-01-07: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-08 data-count=0 title="2026-01-08: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-09 data-count=0 title="2026-01-09: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-10 data-count=0 title="2026-01-10: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-11 data-count=0 title="2026-01-11: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-12 data-count=0 title="2026-01-12: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-13 data-count=0 title="2026-01-13: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-14 data-count=0 title="2026-01-14: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-15 data-count=0 title="2026-01-15: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-16 data-count=0 title="2026-01-16: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-17 data-count=0 title="2026-01-17: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-18 data-count=0 title="2026-01-18: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-19 data-count=0 title="2026-01-19: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-20 data-count=0 title="2026-01-20: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-21 data-count=0 title="2026-01-21: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-22 data-count=0 title="2026-01-22: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-23 data-count=0 title="2026-01-23: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-24 data-count=0 title="2026-01-24: 0 篇"></div><div class="contribution-cell level-0" data-date=2026-01-25 data-count=1 title="2026-01-25: 1 篇"></div><div class="contribution-cell level-4" data-date=2026-01-26 data-count=10 title="2026-01-26: 10 篇"></div><div class="contribution-cell level-0" data-date=2026-01-27 data-count=1 title="2026-01-27: 1 篇"></div><div class="contribution-cell level-2" data-date=2026-01-28 data-count=6 title="2026-01-28: 6 篇"></div><div class="contribution-cell level-1" data-date=2026-01-29 data-count=3 title="2026-01-29: 3 篇"></div><div class="contribution-cell level-1" data-date=2026-01-30 data-count=3 title="2026-01-30: 3 篇"></div><div class="contribution-cell level-1" data-date=2026-01-31 data-count=4 title="2026-01-31: 4 篇"></div><div class="contribution-cell level-2" data-date=2026-02-01 data-count=5 title="2026-02-01: 5 篇"></div><div class="contribution-cell level-2" data-date=2026-02-02 data-count=6 title="2026-02-02: 6 篇"></div></div><div class=contribution-legend><span>少</span><div class=legend-cells><div class="contribution-cell level-0"></div><div class="contribution-cell level-1"></div><div class="contribution-cell level-2"></div><div class="contribution-cell level-3"></div><div class="contribution-cell level-4"></div></div><span>多</span></div></div><div class=card-footer><div class=footer-logo><img src=https://simons.qzz.io/site/logo/logo.jpg alt=短松江月 class="max-h-8 object-contain" loading=lazy>
<span>短松江月</span></div><div class=p-1><div class=footer-qr id=qrcodeSmall></div></div></div></div></section><section><div class=card-actions><button onclick=generateShareImage() class="action-btn action-btn-primary">
<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4-4 4m0 0-4-4m4 4V4"/></svg>
下载分享图片
</button>
<button onclick=downloadQRCode() class="action-btn action-btn-secondary">
<svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 4v1m6 11h2m-6 0h-2v4m0-11v3m0 0h.01M12 12h4.01M16 20h4M4 12h4m12 0h.01M5 8h2a1 1 0 001-1V5A1 1 0 007 4H5A1 1 0 004 5v2a1 1 0 001 1zm12 0h2a1 1 0 001-1V5a1 1 0 00-1-1h-2a1 1 0 00-1 1v2a1 1 0 001 1zM5 20h2a1 1 0 001-1v-2a1 1 0 00-1-1H5a1 1 0 00-1 1v2a1 1 0 001 1z"/></svg>
保存二维码</button></div></section></div></div></div><script src=https://cdn.jsdelivr.net/npm/qrcode@1.2.2/build/qrcode.min.js></script><script src=https://cdn.jsdelivr.net/npm/html2canvas@1.4.1/dist/html2canvas.min.js></script><script>const shareData={title:"人工智能中的数学基础",description:`<h2 id="1-向量空间-vector-space">1. 向量空间 (Vector Space)</h2>
<h3 id="数学概念">数学概念</h3>
<p><strong>向量空间</strong>是线性代数的核心概念，它是一个满足特定运算规则的集合。</p>
<p><strong>定义要素</strong>：</p>
<ul>
<li><strong>域 F</strong>：通常是实数域 ℝ 或复数域 ℂ</li>
<li><strong>向量集合 V</strong>：非空集合</li>
<li><strong>两种运算</strong>：
<ul>
<li>加法：V × V → V</li>
<li>数 …</li></ul></li></ul>`,url:"https://simons.qzz.io/post/2026/02/basic_concepts/",author:"simons",siteTitle:"短松江月"},shareTrigger=document.querySelector(".share-trigger-btn"),sharePanel=document.getElementById("sharePanel"),closeBtn=document.querySelector(".share-close-btn");shareTrigger?.addEventListener("click",()=>{sharePanel.classList.add("active"),document.body.style.overflow="hidden"}),closeBtn?.addEventListener("click",closeSharePanel),sharePanel?.addEventListener("click",e=>{e.target===sharePanel&&closeSharePanel()});function closeSharePanel(){sharePanel.classList.remove("active"),document.body.style.overflow=""}document.addEventListener("keydown",e=>{e.key==="Escape"&&sharePanel.classList.contains("active")&&closeSharePanel()});function generateQRCode(){const e=document.getElementById("qrcodeSmall");if(!e)return;e.innerHTML="";const t=document.createElement("canvas");e.appendChild(t),QRCode.toCanvas(t,shareData.url,{width:80,height:80,margin:0,color:{dark:"#1e40af",light:"#ffffff"}},function(e){e&&(console.error("QRCode生成失败:",e),generateQRCodeFallback())})}function generateQRCodeFallback(){const e=document.getElementById("qrcodeSmall");if(!e)return;e.innerHTML="";try{new QRCode(e,{text:shareData.url,width:80,height:80,colorDark:"#1e40af",colorLight:"#ffffff",correctLevel:QRCode.CorrectLevel.H})}catch(e){console.error("备用二维码生成也失败:",e)}}document.addEventListener("DOMContentLoaded",function(){generateQRCode()});function downloadQRCode(){const e=document.createElement("canvas");QRCode.toCanvas(e,shareData.url,{width:512,height:512,margin:2,color:{dark:"#1e40af",light:"#ffffff"}},t=>{if(!t){const t=document.createElement("a");t.download=`qrcode-${shareData.title.replace(/\s+/g,"-")}.png`,t.href=e.toDataURL("image/png"),t.click(),showToast("✓ 二维码已下载")}})}function shareTo(e){const n=encodeURIComponent(shareData.url),s=encodeURIComponent(shareData.title),o=encodeURIComponent(shareData.description);let t="";switch(e){case"wechat":showToast("📱 请使用微信扫描二维码分享");return;case"qq":t=`https://connect.qq.com/widget/shareqq/index.html?url=${n}&title=${s}&summary=${o}`;break;case"weibo":t=`http://service.weibo.com/share/share.php?url=${n}&title=${s}`;break;case"twitter":t=`https://twitter.com/intent/tweet?url=${n}&text=${s}`;break;case"linkedin":t=`https://www.linkedin.com/shareArticle?mini=true&url=${n}&title=${s}&summary=${o}`;break}t&&(window.open(t,"_blank","width=600,height=400"),updateShareCount())}function copyLink(){navigator.clipboard.writeText(shareData.url).then(()=>showToast("✓ 链接已复制到剪贴板")).catch(()=>showToast("✗ 复制失败，请手动复制")),updateShareCount()}function generateShareImage(){const e=document.getElementById("shareCard");if(!e)return;showToast("🎨 正在生成分享图片..."),html2canvas(e,{backgroundColor:"#ffffff",scale:2,useCORS:!0,allowTaint:!0,logging:!1}).then(e=>{const t=document.createElement("a");t.download=`share-${shareData.title.replace(/\s+/g,"-")}.png`,t.href=e.toDataURL("image/png"),t.click(),showToast("✓ 分享图片已生成"),updateShareCount()}).catch(()=>{showToast("✗ 生成失败，请重试")})}function updateShareCount(){const n=(new Date).toDateString();let t=JSON.parse(localStorage.getItem("shareStats")||"{}"),e=t[window.location.pathname]||{total:0,lastDate:"",today:0};e.total+=1,e.today=e.lastDate===n?e.today+1:1,e.lastDate=n,t[window.location.pathname]=e,localStorage.setItem("shareStats",JSON.stringify(t)),document.getElementById("share-count").textContent=e.total,document.getElementById("today-share").textContent=e.today}function initShareStats(){const t=JSON.parse(localStorage.getItem("shareStats")||"{}"),e=t[window.location.pathname]||{total:0,today:0};document.getElementById("share-count").textContent=e.total,document.getElementById("today-share").textContent=e.today}function showToast(e){const n=document.querySelector(".share-toast");n&&n.remove();const t=document.createElement("div");t.className="share-toast",t.textContent=e,document.body.appendChild(t),setTimeout(()=>t.classList.add("show"),10),setTimeout(()=>{t.classList.remove("show"),setTimeout(()=>t.remove(),300)},3e3)}document.addEventListener("DOMContentLoaded",()=>{generateQRCode(),initShareStats()})</script></div><nav class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg !leading-[1.2] *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"><a class="ltr:pr-3 rtl:pl-3" href=https://simons.qzz.io/post/2026/02/basic_math/><span class="ltr:mr-1.5 rtl:ml-1.5">←</span><span>MATLAB 简明教程</span></a>
<a class="ltr:ml-auto rtl:mr-auto justify-end pl-3" href=https://simons.qzz.io/post/2026/02/what_is_amm/><span>自动做市商是什么？</span><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a></nav><div class="mt-12 rounded-xl" style=text-align:center><button class=feedback-trigger onclick=toggleFeedback()>建议 / 反馈</button><div class="feedback-form hidden"><p>感谢你的提议，我将会尽快使用回复您！（此反馈将使用您的邮箱发送）</p><form id=feedback-form onsubmit=sendFeedback(event)><input type=text name=name placeholder=怎么称呼？ required>
<textarea name=message placeholder=请输入您的建议或意见... required></textarea>
<button type=submit>发送</button></form></div><style>.feedback-trigger{background:#007bff;color:#fff;border:none;padding:.25rem .5rem;border-radius:12px;cursor:pointer;box-shadow:0 2px 5px rgba(0,0,0,.2);margin:1rem}.feedback-form{background:#fff;padding:20px;border-radius:8px;box-shadow:0 2px 10px rgba(0,0,0,.1);margin-bottom:10px}.feedback-form.hidden{display:none}.feedback-form input,.feedback-form textarea{width:100%;margin-bottom:10px;padding:8px;border:1px solid #ddd;border-radius:4px}.feedback-form textarea{height:100px;resize:vertical}.feedback-form button{width:100%;background:#007bff;color:#fff;border:none;padding:8px;border-radius:4px;cursor:pointer}</style><script>function toggleFeedback(){document.querySelector(".feedback-form").classList.toggle("hidden")}function sendFeedback(e){e.preventDefault();const t=e.target,n=`mailto:reggiesimons2cy@gmail.com?subject=https://simons.qzz.io/ Feedback from ${t.name.value}&body=${encodeURIComponent(t.message.value)}%0D%0A%0D%0AFrom: ${t.name.value}%0D%0AEmail: ${t.email.value}`;window.location.href=n}</script></div><div class="mt-24 w-100rem" id=disqus_thread></div><script>const disqusShortname="caoyang2002.vercel.app",script=document.createElement("script");script.src="https://"+disqusShortname+".disqus.com/embed.js",script.setAttribute("data-timestamp",+new Date),document.head.appendChild(script)</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.1/mermaid.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.1/mermaid.min.js></script><div class="giscus mt-24"></div><script src=https://giscus.app/client.js data-repo=caoyang2002/caoyang2002 data-repo-id=R_kgDONgnnzg data-category=Announcements data-category-id=DIC_kwDONgnnzs4ClayH data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><div class="ml-2 mr-4"><button class=mobile-toc-toggle>
<svg t="1737363365612" class="icon" viewBox="0 0 1024 1024" p-id="7154" width="32" height="32"><path d="M811.6 264.1H378.2c-19.8.0-36-16.2-36-36s16.2-36 36-36h433.5c19.8.0 36 16.2 36 36-.1 19.8-16.3 36-36.1 36zm0 258H378.2c-19.8.0-36-16.2-36-36s16.2-36 36-36h433.5c19.8.0 36 16.2 36 36-.1 19.8-16.3 36-36.1 36zm0 258H378.2c-19.8.0-36-16.2-36-36s16.2-36 36-36h433.5c19.8.0 36 16.2 36 36-.1 19.8-16.3 36-36.1 36z" fill="#223D60" p-id="7155"/><path d="M210.2 229m-37.9.0a37.9 37.9.0 1075.8.0 37.9 37.9.0 10-75.8.0z" fill="#223D60" p-id="7156"/><path d="M210.2 487m-37.9.0a37.9 37.9.0 1075.8.0 37.9 37.9.0 10-75.8.0z" fill="#223D60" p-id="7157"/><path d="M210.2 745m-37.9.0a37.9 37.9.0 1075.8.0 37.9 37.9.0 10-75.8.0z" fill="#223D60" p-id="7158"/></svg></button><aside class="toc-aside mr-4"><div class=toc-container><div class=toc-header><h3 class=toc-title>目录</h3><button class=toc-close>
<svg viewBox="0 0 24 24" width="24" height="24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18 18 6M6 6l12 12"/></svg></button></div><nav id=TableOfContents class=toc><nav id=TableOfContents><ul><li><ul><li><a href=#1-向量空间-vector-space>1. 向量空间 (Vector Space)</a><ul><li><a href=#数学概念>数学概念</a></li><li><a href=#在机器学习中的应用>在机器学习中的应用</a></li><li><a href=#python实现>Python实现</a></li></ul></li><li><a href=#2-线性组合-linear-combination>2. 线性组合 (Linear Combination)</a><ul><li><a href=#数学概念-1>数学概念</a></li><li><a href=#在机器学习中的应用-1>在机器学习中的应用</a></li><li><a href=#python实现-1>Python实现</a></li></ul></li><li><a href=#3-生成空间-span>3. 生成空间 (Span)</a><ul><li><a href=#数学概念-2>数学概念</a></li><li><a href=#在机器学习中的应用-2>在机器学习中的应用</a></li><li><a href=#python实现-2>Python实现</a></li></ul></li><li><a href=#4-欧几里得空间-euclidean-space>4. 欧几里得空间 (Euclidean Space)</a><ul><li><a href=#数学概念-3>数学概念</a></li><li><a href=#在机器学习中的应用-3>在机器学习中的应用</a></li><li><a href=#python实现-3>Python实现</a></li></ul></li><li><a href=#5-线性无关-linear-independence>5. 线性无关 (Linear Independence)</a><ul><li><a href=#数学概念-4>数学概念</a></li><li><a href=#在机器学习中的应用-4>在机器学习中的应用</a></li><li><a href=#python实现-4>Python实现</a></li></ul></li><li><a href=#6-基-basis>6. 基 (Basis)</a><ul><li><a href=#数学概念-5>数学概念</a></li><li><a href=#在机器学习中的应用-5>在机器学习中的应用</a></li><li><a href=#python实现-5>Python实现</a></li></ul></li><li><a href=#7-维数-dimension>7. 维数 (Dimension)</a><ul><li><a href=#数学概念-6>数学概念</a></li><li><a href=#在机器学习中的应用-6>在机器学习中的应用</a></li><li><a href=#python实现-6>Python实现</a></li></ul></li><li><a href=#8-标准基-standard-basis>8. 标准基 (Standard Basis)</a><ul><li><a href=#数学概念-7>数学概念</a></li><li><a href=#python实现-7>Python实现</a></li></ul></li><li><a href=#9-范数-norm>9. 范数 (Norm)</a><ul><li><a href=#数学概念-8>数学概念</a></li><li><a href=#在机器学习中的应用-7>在机器学习中的应用</a></li><li><a href=#python实现-8>Python实现</a></li></ul></li></ul></li></ul></nav></nav></div></aside><style>.toc-aside{position:fixed;top:6rem;bottom:4rem;right:0;width:16rem;z-index:100;transition:transform .3s ease}.toc-container{background:#fff;height:100%;border-radius:.5rem .5rem .5rem .5rem;box-shadow:-2px 0 8px rgba(0,0,0,.1);display:flex;flex-direction:column}.toc-header{position:sticky;border-radius:.5rem .5rem 0 0;top:0;background:#fff;padding:1rem;border-bottom:1px solid #e5e7eb;display:flex;justify-content:space-between;align-items:center;z-index:10}.toc-title{margin:0;font-size:1rem;font-weight:600}.mobile-toc-toggle{display:none;position:fixed;top:6rem;right:1rem;z-index:99;width:3rem;height:3rem;border-radius:50%;background:#fff;border:1px solid #e5e7eb;box-shadow:0 2px 8px rgba(0,0,0,.1);color:#4b5563;cursor:pointer;transition:all .2s}.mobile-toc-toggle:hover{background:#f3f4f6}.mobile-toc-toggle .menu-icon{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%)}.toc-close{padding:.5rem;background:0 0;border:none;color:--bg;cursor:pointer;transition:all .2s}.toc-close:hover{color:#111827}.toc{flex:1;overflow-y:auto;padding:1rem;scrollbar-gutter:stable}.toc ul{list-style:none;padding-left:1rem;margin:0}.toc li{margin:.5rem 0}.toc a{display:block;padding:.25rem .5rem;color:#4b5563;text-decoration:none;border-radius:.25rem;transition:all .2s}.toc a:hover{background-color:#f3f4f6;color:#111827}.toc a:active{background-color:#f3f4f6;color:#111827;font-weight:500}.toc::-webkit-scrollbar{width:4px}.toc::-webkit-scrollbar-track{background:0 0}.toc::-webkit-scrollbar-thumb{background-color:#d1d1d1;border-radius:4px}@media(max-width:912px){.mobile-toc-toggle{display:flex;justify-content:center;align-items:center}.toc-aside{transform:translateX(100%);width:80vw;max-width:20rem}.toc-aside.show{transform:translateX(0)}}h1,h2,h3,h4,h5,h6{scroll-margin-top:100px}</style><script>document.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".toc-aside"),t=document.querySelector(".mobile-toc-toggle"),n=document.querySelector(".toc-close");t?.addEventListener("click",()=>{e?.classList.add("show")}),n?.addEventListener("click",()=>{e?.classList.remove("show")}),document.addEventListener("click",n=>{window.innerWidth<=912&&e?.classList.contains("show")&&!e.contains(n.target)&&!t?.contains(n.target)&&e.classList.remove("show")});const s=new IntersectionObserver(e=>{e.forEach(e=>{const t=e.target.getAttribute("id"),n=document.querySelector(`.toc a[href="#${t}"]`);e.intersectionRatio>0&&(document.querySelectorAll(".toc a.active").forEach(e=>{e.classList.remove("active")}),n?.classList.add("active"))})},{rootMargin:"-20% 0px -80% 0px"});document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]").forEach(e=>{s.observe(e)})})</script></div></div><footer class="flex items-center text-xs uppercase h-8"><div class="mr-auto opacity-60">&copy; 2026
<a class=link href=https://simons.qzz.io/>短松江月</a></div><div><link rel=stylesheet href=//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><p class="link mx-6 opacity-60">本站累计访问次数
<span id=busuanzi_value_page_pv><i class="fa fa-spinner fa-spin"></i></span></p></div><a class="link mx-6 opacity-60" href=https://gohugo.io/ rel=noopener target=_blank>powered by hugo️️</a>️
<a class="link mx-6 opacity-60" href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>hugo-paper</a>
<a class="link opacity-60" href=https://caoyang2002.github.io/hugo-focus/ rel=noopener target=_blank>hugo-focus</a></footer><style>footer{position:fixed;bottom:0;left:0;right:0;z-index:50;width:100%;padding:.5rem;padding-bottom:calc(.5rem + var(--safe-padding-bottom));padding-left:max(.5rem,var(--safe-padding-left));padding-right:max(.5rem,var(--safe-padding-right));display:flex;justify-content:center;align-items:center;backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(12px);background:rgba(255,255,255,.85);border-top:1px solid rgba(255,255,255,.3);box-shadow:0 -4px 20px rgba(0,0,0,5%)}.dark footer{background:rgba(0,0,0,.85);border-top-color:rgba(255,255,255,.1)}.footer-content{width:100%;max-width:var(--w);margin:0 auto;padding:0 1rem;display:flex;flex-direction:row;align-items:center;justify-content:space-between;gap:1rem}.footer-element{padding:.75rem 1.5rem;font-size:.75rem;text-transform:uppercase;letter-spacing:.05em;opacity:.8;border-radius:.5rem;background:rgba(255,255,255,.1);backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(4px);transition:all .2s ease}.footer-element:hover{opacity:1;background:rgba(255,255,255,.2)}.dark .footer-element{background:rgba(255,255,255,5%)}.dark .footer-element:hover{background:rgba(255,255,255,.1)}@media(max-width:768px){footer{padding-top:.5rem;padding-bottom:calc(.5rem + env(safe-area-inset-bottom))}.footer-content{padding:0 .5rem;gap:.5rem}.footer-element{padding:.5rem 1rem;font-size:.75rem}}@media(min-width:768px){.footer-element{font-size:.875rem}}@media(min-width:1024px){.footer-content{padding:0 2rem;gap:2rem}.footer-element{padding:.75rem 2rem}}</style><script>async function loadScript(e,t=15e3){return new Promise((n,s)=>{if(!e){n();return}const a=document.querySelector(`script[src="${e}"]`);if(a){n();return}const o=document.createElement("script");o.src=e,o.async=!0;const i=setTimeout(()=>{o.remove(),s(new Error(`Script loading timed out: ${e}`))},t);o.onload=()=>{clearTimeout(i),n()},o.onerror=t=>{clearTimeout(i),o.remove(),s(new Error(`Failed to load script: ${e}`))},document.head.appendChild(o)})}const runners={python:{cdn:"https://cdn.jsdelivr.net/pyodide/v0.25.0/full/pyodide.js",init:async()=>{const e=await loadPyodide({indexURL:"https://cdn.jsdelivr.net/pyodide/v0.25.0/full/"});return await e.loadPackage(["numpy","pandas","matplotlib"]),e},execute:async e=>{const t=runtimeInstances.python;let n=[];t.globals.set("print",(...e)=>{n.push(e.map(String).join(" "))});try{const s=await t.runPythonAsync(e),o=s!==0[0]?String(s):"";return[...n,o].filter(Boolean).join(`
`)||"(无输出)"}catch(e){throw new Error(`Python错误: ${e.message}`)}}},py:{cdn:null,init:async()=>runners.python.init(),execute:async e=>runners.python.execute(e)},r:{cdn:"https://webr.r-wasm.org/v0.3.1/webr.mjs",init:async()=>{try{const{WebR:t}=await import("https://webr.r-wasm.org/v0.3.1/webr.mjs"),e=new t;return await e.init(),e}catch(e){throw console.error("WebR 初始化失败:",e),new Error(`R runtime initialization error: ${e.message}`)}},execute:async e=>{try{const s=runtimeInstances.r,n=await new s.Shelter,t=await n.captureR(e);if(n.purge(),t.output&&t.output.length>0){const e=t.output.filter(e=>e.type==="stdout").map(e=>e.data).join(`
`).trim();return e||"(无输出)"}return"(无输出)"}catch(e){throw console.error("R 执行错误:",e),new Error(`R execution error: ${e.message}`)}}},javascript:{cdn:null,init:async()=>({}),execute:async e=>{let t=[];const n=console.log,s=console.error,o=console.warn;console.log=(...e)=>{t.push(e.map(String).join(" ")),n.apply(console,e)},console.error=(...e)=>{t.push("错误: "+e.map(String).join(" ")),s.apply(console,e)},console.warn=(...e)=>{t.push("警告: "+e.map(String).join(" ")),o.apply(console,e)};try{const s=new Function(e),n=s();n!==0[0]&&t.push("返回值: "+n)}catch(e){throw new Error(`执行错误: ${e.message}`)}finally{console.log=n,console.error=s,console.warn=o}return t.join(`
`)||"(无输出)"}},js:{cdn:null,init:async()=>runners.javascript.init(),execute:async e=>runners.javascript.execute(e)},typescript:{cdn:"https://cdn.jsdelivr.net/npm/typescript@5.3.3/lib/typescript.min.js",init:async()=>(await loadScript("https://cdn.jsdelivr.net/npm/typescript@5.3.3/lib/typescript.min.js"),window.ts),execute:async e=>{let t=[];const n=console.log;console.log=(...e)=>t.push(e.join(" "));try{const t=ts.transpileModule(e,{compilerOptions:{target:ts.ScriptTarget.ES2020,module:ts.ModuleKind.None}}).outputText;eval(t)}catch(e){throw new Error(`TypeScript错误: ${e.message}`)}finally{console.log=n}return t.join(`
`)||"(无输出)"}},ts:{cdn:null,init:async()=>runners.typescript.init(),execute:async e=>runners.typescript.execute(e)},rust:{cdn:null,init:async()=>({}),execute:async e=>{const t=await fetch("https://play.rust-lang.org/execute",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({channel:"stable",mode:"debug",edition:"2021",crateType:"bin",tests:!1,code:e})});if(!t.ok)throw new Error(`HTTP错误: ${t.status}`);const n=await t.json();if(n.success)return n.stdout||"(无输出)";throw new Error(n.stderr||"编译失败")}},rs:{cdn:null,init:async()=>runners.rust.init(),execute:async e=>runners.rust.execute(e)},go:{cdn:null,init:async()=>({}),execute:async e=>{const t=await fetch("https://play.golang.org/compile",{method:"POST",headers:{"Content-Type":"application/x-www-form-urlencoded"},body:`version=2&body=${encodeURIComponent(e)}&withVet=true`});if(!t.ok)throw new Error(`HTTP错误: ${t.status}`);const n=await t.json();if(n.Errors)throw new Error(n.Errors);return n.Events?.map(e=>e.Message).join(`
`)||"(无输出)"}},c:{cdn:null,init:async()=>({}),execute:async e=>{const t=await fetch("https://godbolt.org/api/compiler/cg132/compile",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({source:e,options:{userArguments:"-std=c17 -O2",executeParameters:{args:[],stdin:""},compilerOptions:{executorRequest:!0}}})});if(!t.ok)throw new Error(`编译失败: ${t.status}`);const n=await t.json();if(n.code!==0)throw new Error(n.stderr||"执行失败");const s=n.stdout?.map(e=>e.text).join(`
`)||"";return s||"(无输出)"}},cpp:{cdn:null,init:async()=>({}),execute:async e=>{const t=await fetch("https://godbolt.org/api/compiler/g132/compile",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({source:e,options:{userArguments:"-std=c++20 -O2",executeParameters:{args:[],stdin:""},compilerOptions:{executorRequest:!0}}})});if(!t.ok)throw new Error(`编译失败: ${t.status}`);const n=await t.json();if(n.code!==0)throw new Error(n.stderr||"执行失败");const s=n.stdout?.map(e=>e.text).join(`
`)||"";return s||"(无输出)"}},php:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"php-8.3.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},ruby:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"ruby-3.3.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},rb:{cdn:null,init:async()=>runners.ruby.init(),execute:async e=>runners.ruby.execute(e)},swift:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"swift-5.9.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},kotlin:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://api.kotlinlang.org/api/1.9.21/compiler/run",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({args:"",confType:"java",files:[{name:"File.kt",text:e,publicId:null}]})}),t=await n.json();if(t.errors?.length>0)throw new Error(t.errors.map(e=>e.message).join(`
`));return t.text||"(无输出)"}},kt:{cdn:null,init:async()=>runners.kotlin.init(),execute:async e=>runners.kotlin.execute(e)},scala:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"scala-3.3.1",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},haskell:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"ghc-9.6.3",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},hs:{cdn:null,init:async()=>runners.haskell.init(),execute:async e=>runners.haskell.execute(e)},perl:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"perl-5.38.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},pl:{cdn:null,init:async()=>runners.perl.init(),execute:async e=>runners.perl.execute(e)},lua:{cdn:"https://fengari.io/fengari-web.js",init:async()=>(await loadScript("https://fengari.io/fengari-web.js"),fengari),execute:async e=>{const t=runtimeInstances.lua;let s=[];const n=t.lauxlib.luaL_newstate();t.lauxlib.luaL_openlibs(n),t.lua.lua_pushcfunction(n,function(e){const o=t.lua.lua_gettop(e),n=[];for(let s=1;s<=o;s++)n.push(t.lua.lua_tojsstring(e,s));return s.push(n.join("	")),0}),t.lua.lua_setglobal(n,"print");const o=t.lauxlib.luaL_dostring(n,e);if(o!==0){const e=t.lua.lua_tojsstring(n,-1);throw new Error(e)}return s.join(`
`)||"(无输出)"}},zig:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"zig-0.11.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},nim:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"nim-2.0.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},d:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"dmd-2.105.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},fortran:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"gfortran-13.2.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},f90:{cdn:null,init:async()=>runners.fortran.init(),execute:async e=>runners.fortran.execute(e)},sql:{cdn:"https://cdn.jsdelivr.net/npm/sql.js@1.10.0/dist/sql-wasm.js",init:async()=>(await loadScript("https://cdn.jsdelivr.net/npm/sql.js@1.10.0/dist/sql-wasm.js"),await initSqlJs({locateFile:e=>`https://cdn.jsdelivr.net/npm/sql.js@1.10.0/dist/${e}`})),execute:async e=>{const s=runtimeInstances.sql,n=new s.Database,t=[],o=e.split(";").filter(e=>e.trim());for(const e of o)try{if(e.trim().toUpperCase().startsWith("SELECT")){const s=n.exec(e);s.length>0&&s.forEach(({columns:e,values:n})=>{t.push(e.join(" | ")),t.push("-".repeat(e.join(" | ").length)),n.forEach(e=>t.push(e.join(" | "))),t.push("")})}else n.run(e),t.push(`✓ 执行成功: ${e.substring(0,50)}...`)}catch(e){t.push(`✗ 错误: ${e.message}`)}return t.join(`
`)||"查询完成"}},bash:{cdn:null,init:async()=>({}),execute:async e=>{const n=e.split(`
`),t=[];for(const s of n){const e=s.trim();if(!e||e.startsWith("#"))continue;if(e.startsWith("echo ")){const n=e.substring(5).replace(/^["']|["']$/g,"");t.push(n)}else e==="pwd"?t.push("/home/user"):e.startsWith("ls")?t.push("file1.txt  file2.txt  directory/"):e.startsWith("date")?t.push((new Date).toString()):e.startsWith("whoami")?t.push("user"):e.startsWith("uname")?t.push("Linux"):t.push(`[模拟执行] ${e}`)}return t.join(`
`)||"(无输出)"}},sh:{cdn:null,init:async()=>runners.bash.init(),execute:async e=>runners.bash.execute(e)},shell:{cdn:null,init:async()=>runners.bash.init(),execute:async e=>runners.bash.execute(e)},lisp:{cdn:"https://unpkg.com/jscl@0.8.2/jscl.js",init:async()=>(await loadScript("https://unpkg.com/jscl@0.8.2/jscl.js"),window.jscl),execute:async e=>{const n=runtimeInstances.lisp;let t=[];const s=console.log;console.log=(...e)=>{const n=e.join(" ");!n.includes("jscl.js:")&&!n.includes("loading")&&t.push(n)};try{const s=n.evaluateString(e);return t.length>0?t.join(`
`):s!=null?s===!1?"NIL":String(s):"(无输出)"}catch(e){throw new Error(`Lisp错误: ${e.message}`)}finally{console.log=s}}},pascal:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"fpc-3.2.2",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},pas:{cdn:null,init:async()=>runners.pascal.init(),execute:async e=>runners.pascal.execute(e)},erlang:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"erlang-26.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},erl:{cdn:null,init:async()=>runners.erlang.init(),execute:async e=>runners.erlang.execute(e)},elixir:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"elixir-1.15.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},ex:{cdn:null,init:async()=>runners.elixir.init(),execute:async e=>runners.elixir.execute(e)},ocaml:{cdn:null,init:async()=>({}),execute:async e=>{const n=await fetch("https://wandbox.org/api/compile.json",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({code:e,compiler:"ocaml-5.0.0",options:"",stdin:""})}),t=await n.json();if(t.status!=="0")throw new Error(t.compiler_error||t.program_error||"执行失败");return t.program_output||"(无输出)"}},ml:{cdn:null,init:async()=>runners.ocaml.init(),execute:async e=>runners.ocaml.execute(e)},scheme:{cdn:"https://unpkg.com/biwascheme@0.8.0/release/biwascheme.min.js",init:async()=>(await loadScript("https://unpkg.com/biwascheme@0.8.0/release/biwascheme.min.js"),new BiwaScheme.Interpreter),execute:async e=>{const s=runtimeInstances.scheme;let t=[];const n=console.log;console.log=(...e)=>t.push(e.join(" "));try{const o=s.evaluate(e);return console.log=n,t.length>0?t.join(`
`):String(o)}catch(e){throw console.log=n,new Error(`Scheme错误: ${e.message}`)}}},scm:{cdn:null,init:async()=>runners.scheme.init(),execute:async e=>runners.scheme.execute(e)}};let runtimeInstances={};async function initRuntime(e){if(!runners[e])throw new Error(`不支持的语言: ${e}`);try{if(!runtimeInstances[e]){const t=runners[e];t.cdn&&await loadScript(t.cdn),runtimeInstances[e]=await t.init()}return runtimeInstances[e]}catch(t){throw console.error(`Runtime initialization error for ${e}:`,t),new Error(`运行时初始化失败: ${t.message}`)}}async function executeCode(e,t,n){try{await initRuntime(e);const s=await runners[e].execute(t);n.textContent=s,n.parentElement.style.display="block"}catch(t){console.error(`Code execution error for ${e}:`,t),n.textContent=`错误: ${t.message}`,n.parentElement.style.display="block"}}document.addEventListener("DOMContentLoaded",()=>{document.querySelectorAll(".code-playground").forEach(e=>{const s=e.getAttribute("data-language"),t=e.querySelector(".run-button"),o=e.querySelector("code"),n=e.querySelector(".output-content");if(!t||!o||!n){console.warn(`Missing elements for playground with language: ${s}`);return}t.addEventListener("click",async()=>{t.disabled=!0,t.textContent=`加载 ${s} 运行时...`,n.parentElement.style.display="none";try{await executeCode(s,o.textContent,n)}catch(e){n.textContent=`运行时错误: ${e.message}`,n.parentElement.style.display="block"}finally{t.disabled=!1,t.textContent="▶ 运行"}})})})</script><style>.code-playground{border:1px solid #ddd;border-radius:8px;overflow:hidden;margin:1.5rem 0;background:#f8f9fa;box-shadow:0 2px 4px rgba(0,0,0,5%)}.code-playground .code-wrapper{background:#282c34;overflow-x:auto}.code-playground .controls{padding:.75rem;border-top:1px solid #ddd;background:#fff;text-align:center}.code-playground .run-button{padding:.6rem 3.5rem;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:#fff;border:none;border-radius:6px;cursor:pointer;font-size:14px;font-weight:600;transition:all .3s;box-shadow:0 2px 8px rgba(102,126,234,.3)}.code-playground .run-button:hover:not(:disabled){background:linear-gradient(135deg,#764ba2 0%,#667eea 100%);transform:translateY(-1px);box-shadow:0 4px 12px rgba(102,126,234,.4)}.code-playground .run-button:disabled{background:#6c757d;cursor:not-allowed;transform:none;box-shadow:none}.code-playground .output{display:none;border-top:1px solid #ddd;background:#f8f9fa;padding:1rem}.code-playground .output-label{font-weight:700;color:#495057;margin-bottom:.5rem;font-size:13px;text-transform:uppercase;letter-spacing:.5px}.code-playground .output-content{background:#fff;border:1px solid #dee2e6;border-radius:4px;padding:1rem;white-space:pre-wrap;word-wrap:break-word;font-family:consolas,monaco,courier new,monospace;font-size:13px;line-height:1.6;max-height:400px;overflow-y:auto;color:#212529}.code-playground .output-content::-webkit-scrollbar{width:8px}.code-playground .output-content::-webkit-scrollbar-track{background:#f1f1f1}.code-playground .output-content::-webkit-scrollbar-thumb{background:#888;border-radius:4px}.code-playground .output-content::-webkit-scrollbar-thumb:hover{background:#555}@media(prefers-color-scheme:dark){.code-playground{background:#1e1e1e;border-color:#444}.code-playground .controls{background:#2d2d2d;border-color:#444}.code-playground .output{background:#2d2d2d;border-color:#444}.code-playground .output-label{color:#e0e0e0}.code-playground .output-content{background:#1e1e1e;border-color:#444;color:#e0e0e0}.code-playground .output-content::-webkit-scrollbar-track{background:#2d2d2d}.code-playground .output-content::-webkit-scrollbar-thumb{background:#555}.code-playground .output-content::-webkit-scrollbar-thumb:hover{background:#777}}</style></body></html>